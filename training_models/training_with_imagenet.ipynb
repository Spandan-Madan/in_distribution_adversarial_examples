{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose\n",
    "\n",
    "Setting up scripts to train CNN. This was saved as a python file and then used for launching training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/om5/user/smadan/training_scaffold_own/res/loader/multi_attribute_loader.py\n",
      "/om5/user/smadan/training_scaffold_own/res/loader\n",
      "/om5/user/smadan/training_scaffold_own/res/loader/loader.py\n",
      "/om5/user/smadan/training_scaffold_own/res/loader\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function, division\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import antialiased_cnns\n",
    "# from torchvision import datasets, models, transforms\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('/om5/user/smadan/training_scaffold_own/res/')\n",
    "from models.models import get_model\n",
    "from loader.loader import get_loader\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_config = {}\n",
    "wandb_config['num_epochs'] = 50\n",
    "wandb_config['model_arch'] = 'TRULY_SHIFT_INVARIANT'\n",
    "wandb_config['batch_size'] = 100\n",
    "wandb_config['num_classes'] = 11\n",
    "wandb_config['base_lr'] = 0.001\n",
    "wandb_config['use_gpu'] = True\n",
    "wandb_config['run_name'] = 'normalization_test'\n",
    "wandb_config['pretrained'] = False\n",
    "wandb_config['image_size'] = 224\n",
    "wandb_config['dataset_name'] = 'imagenet'\n",
    "wandb_config['normalize'] = True\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loader = get_loader('multi_attribute_loader_file_list_shapenet')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "input_img_size = wandb_config['image_size']\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "loader_new = get_loader('multi_attribute_loader_file_list_imagenet')\n",
    "file_list_root = '/om5/user/smadan/dataset_lists_openmind'\n",
    "att_path = '/om5/user/xboix/data/ImageNet/imagenet_metadata.txt'\n",
    "shuffles = {'train':False,'val':False,'test':False}\n",
    "\n",
    "count=0\n",
    "\n",
    "file_lists = {}\n",
    "dsets = {}\n",
    "dset_loaders = {}\n",
    "dset_sizes = {}\n",
    "for phase in ['train','val']:\n",
    "    file_lists[phase] = \"%s/%s_list_%s.txt\"%(file_list_root,phase,wandb_config['dataset_name'])\n",
    "    dsets[phase] = loader_new(file_lists[phase],att_path, image_transform)\n",
    "    dset_loaders[phase] = torch.utils.data.DataLoader(dsets[phase], batch_size=wandb_config['batch_size'], shuffle = shuffles[phase], num_workers=2,drop_last=True)\n",
    "    dset_sizes[phase] = len(dsets[phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, best_acc, best_model, configs):\n",
    "    if configs.normalize == True:\n",
    "        print('Images will be normalized')\n",
    "    model.eval()\n",
    "\n",
    "    running_corrects = 0\n",
    "    iters = 0\n",
    "    for data in tqdm(dset_loaders['test']):\n",
    "        inputs, labels, image_paths = data\n",
    "        if configs.use_gpu:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "\n",
    "        if configs.normalize == True:\n",
    "            im_means = torch.mean(inputs.view(configs.batch_size, -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            im_stds = torch.std(inputs.view(configs.batch_size, -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            inputs = (inputs - im_means)/im_stds\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        iters += 1\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n",
    "\n",
    "\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['test'])\n",
    "\n",
    "    wandb.log({\"test_accuracy\": epoch_acc})\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    wandb.log({\"best_accuracy\": best_acc})\n",
    "\n",
    "    save_path = '/om5/user/smadan/differentiable_graphics_ml/training_models/saved_models/%s.pt'%configs.run_name\n",
    "    with open(save_path,'wb') as F:\n",
    "        torch.save(best_model, F)\n",
    "\n",
    "    return best_acc, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, configs):\n",
    "    if configs.normalize == True:\n",
    "        print('Images will be normalized')\n",
    "    best_model = model\n",
    "    best_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    iters = 0\n",
    "\n",
    "    for data in tqdm(dset_loaders['train']):\n",
    "        inputs, labels, image_paths = data\n",
    "        if configs.use_gpu:\n",
    "            inputs = inputs.float().cuda()\n",
    "            labels = labels.long().cuda()\n",
    "        else:\n",
    "            print('WARNING: NOT USING GPU!')\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.long()\n",
    "\n",
    "        if configs.normalize == True:\n",
    "            im_means = torch.mean(inputs.view(configs.batch_size, -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            im_stds = torch.std(inputs.view(configs.batch_size, -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            inputs = (inputs - im_means)/im_stds\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iters += 1\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        wandb.log({\"train_running_loss\": running_loss/float(iters*len(labels.data))})\n",
    "        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n",
    "\n",
    "    epoch_loss = float(running_loss) / dset_sizes['train']\n",
    "    epoch_acc = float(running_corrects) / float(dset_sizes['train'])\n",
    "    wandb.log({\"train_accuracy\": epoch_acc})\n",
    "    wandb.log({\"train_loss\": epoch_loss})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model, criterion, optimizer, hyperparameters):\n",
    "    with wandb.init(project=\"pytorch-test\", config=hyperparameters):\n",
    "        if hyperparameters['run_name']:\n",
    "            wandb.run.name = hyperparameters['run_name']\n",
    "        config = wandb.config\n",
    "        best_model = model\n",
    "        best_acc = 0.0\n",
    "\n",
    "        print(config)\n",
    "\n",
    "        print(config.num_epochs)\n",
    "        for epoch_num in range(config.num_epochs):\n",
    "            wandb.log({\"Current Epoch\": epoch_num})\n",
    "            model = train_model(model, criterion, optimizer, config)\n",
    "            best_acc, best_model = test_model(model, best_acc, best_model, config)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dset_loaders['val']:\n",
    "    inputs, labels, paths = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3b1c68d6327c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "paths[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(wandb_config['model_arch'],wandb_config['num_classes'])\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=11, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "child_count = 0\n",
    "for child in model.children():\n",
    "    if child_count < 9:        \n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    child_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for child in model.children():\n",
    "    for param in child.parameters():\n",
    "        print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = wandb_config['base_lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leftover_bad_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e8cb387b3d4ca4aeb17b16dd7526af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/929 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "running_loss = 0\n",
    "num_iters = 0\n",
    "for data in tqdm(dset_loaders['train']):\n",
    "    inputs, labels, image_paths = data\n",
    "    inputs = inputs.float().cuda()\n",
    "    im_means = torch.mean(inputs.view(wandb_config['batch_size'], -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    im_stds = torch.std(inputs.view(wandb_config['batch_size'], -1),dim=1).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    inputs = (inputs - im_means)/im_stds\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        if math.isnan(torch.sum(inputs[i]).item()):\n",
    "            print('found nan')\n",
    "            \n",
    "#     labels = labels.long().cuda()\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(inputs)\n",
    "#     _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     if math.isnan(loss.item()):\n",
    "#         break\n",
    "        \n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     running_loss += loss.item()\n",
    "#     num_iters += 1\n",
    "#     if num_iters % 10 == 0:\n",
    "#         print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file = '../../dataset_lists_openmind/train_list_image_train_v5_shapenet_non_zero.txt'\n",
    "# test_file = '../../dataset_lists_openmind/test_list_image_train_v5_shapenet_non_zero.txt'\n",
    "\n",
    "# train_files_cleaned = []\n",
    "# test_files_cleaned = []\n",
    "\n",
    "# with open(train_file,'r') as F:\n",
    "#     content = F.readlines()\n",
    "# train_files = [c.rstrip() for c in content]\n",
    "\n",
    "# with open(test_file,'r') as F:\n",
    "#     content = F.readlines()\n",
    "# test_files = [c.rstrip() for c in content]\n",
    "\n",
    "# train_files_cleaned = [i for i in train_files if i not in leftover_bad_files]\n",
    "# test_files_cleaned = [i for i in test_files if i not in leftover_bad_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_files_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train_file = '../../dataset_lists_openmind/train_list_image_train_v5_shapenet_zero_removed.txt'\n",
    "# new_test_file = '../../dataset_lists_openmind/test_list_image_train_v5_shapenet_zero_removed.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(new_train_file,'w') as F:\n",
    "#     for i in train_files_cleaned:\n",
    "#         print(i, file =F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(new_test_file,'w') as F:\n",
    "#     for i in test_files_cleaned:\n",
    "#         print(i, file =F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_corrects = 0\n",
    "# count = 0\n",
    "# for data in tqdm(dset_loaders['test']):\n",
    "#     inputs, labels, image_paths = data\n",
    "#     inputs = inputs.float().cuda()\n",
    "#     labels = labels.long().cuda()\n",
    "#     outputs = model(inputs)\n",
    "#     corrects = torch.sum(torch.argmax(outputs, dim=1) == labels).item()\n",
    "#     total_corrects += corrects\n",
    "#     count += len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr = wandb_config['base_lr'])\n",
    "\n",
    "if wandb_config['use_gpu']:\n",
    "    criterion.cuda()\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "\n",
    "\n",
    "\n",
    "best_final_model = model_pipeline(model, criterion, optimizer_ft, wandb_config)\n",
    "\n",
    "save_path = '/om5/user/smadan/differentiable_graphics_ml/training_models/saved_models/%s_final.pt'%wandb_config['run_name']\n",
    "\n",
    "with open(save_path,'wb') as F:\n",
    "    torch.save(best_final_model,F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
