{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adapted-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "from utils import MLP\n",
    "from utils import CMA_info\n",
    "import utils\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "related-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-range",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lovely-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "randin = torch.rand((1,3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "soviet-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nn.Conv2d(3,64,5)\n",
    "layer_2 = nn.MaxPool2d(2)\n",
    "layer_7 = nn.AdaptiveAvgPool2d((3,3))\n",
    "#         layer_3 = nn.Conv2d(64,64,3)\n",
    "#         layer_4 = nn.MaxPool2d(2)\n",
    "#         layer_5 = nn.Conv2d(64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adjustable-theorem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_7(layer_1(randin)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intelligent-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layer_1 = nn.Conv2d(3,64,5)\n",
    "        layer_2 = nn.MaxPool2d(2)\n",
    "#         layer_3 = nn.Conv2d(64,64,3)\n",
    "#         layer_4 = nn.MaxPool2d(2)\n",
    "#         layer_5 = nn.Conv2d(64,64,3)\n",
    "#         layer_6 = nn.MaxPool2d(2)\n",
    "        layer_7 = nn.AdaptiveAvgPool2d((3,3))\n",
    "        layer_8 = nn.Dropout(p=0.5,inplace=False)\n",
    "        layer_9 = nn.Linear(64*3*3, 2)\n",
    "#         layer_10 = nn.Linear(64,2)\n",
    "        \n",
    "#         layer_9 = nn.Linear(64*3*3, 512)\n",
    "#         layer_10 = nn.Linear(512,128)\n",
    "#         layer_11 = nn.Linear(128,2)\n",
    "\n",
    "        self.features_list = [layer_1, nn.ReLU(inplace=True),layer_7, nn.Flatten()]\n",
    "        self.classifier_list = [layer_9]\n",
    "        \n",
    "\n",
    "#         self.features_list = [layer_1, nn.ReLU(inplace=True),layer_2,\n",
    "#                               layer_3, nn.ReLU(inplace=True),layer_4,\n",
    "#                               layer_5, nn.ReLU(inplace=True),layer_6, \n",
    "#                               layer_7, nn.Flatten()]\n",
    "#         self.classifier_list = [layer_8,layer_9, nn.ReLU(inplace=True),\n",
    "#                                 layer_10, nn.ReLU(inplace=True),\n",
    "#                                 layer_11, nn.ReLU(inplace=True)]\n",
    "        \n",
    "        self.features = nn.Sequential(*self.features_list)\n",
    "        self.classifier = nn.Sequential(*self.classifier_list)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "behavioral-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-grant",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "historic-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_limits(mean,std):\n",
    "    A = 3.45*std #b-a\n",
    "    B = mean*2 #a+b\n",
    "    b = (B+A)/2\n",
    "    a = b - A\n",
    "    return a,b\n",
    "\n",
    "input_shape = ((50,3,32,32))\n",
    "\n",
    "test_min = -1\n",
    "test_max= 1\n",
    "\n",
    "test_limits = [test_min, test_max]\n",
    "\n",
    "num_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regulated-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits_1 = get_uniform_limits(0.2,0.225)\n",
    "limits_2 = get_uniform_limits(0.7,0.225)\n",
    "\n",
    "limits = limits_1 + limits_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excited-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = [-10,10,20,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "modular-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "innocent-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "equal-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "imported-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(custom_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "second-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = utils.make_image_samples([5000,3,32,32], limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "looking-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(dset[0].shape[0])\n",
    "np.random.shuffle(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "saving-marks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbf33ac6cce47ed8074f7e6aa921c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19238229095935822 tensor(1., device='cuda:0')\n",
      "0.09828417748212814 tensor(1., device='cuda:0')\n",
      "0.06392990797758102 tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100)):  # loop over the dataset multiple times\n",
    "    corrects = 0\n",
    "    totals = 0\n",
    "    for iter_ in range(10):\n",
    "        noise_dset = [dset[0][s][iter_*1000:iter_*1000+1000], dset[1][s][iter_*1000:iter_*1000+1000]]\n",
    "        noisy_inputs = noise_dset[0].to(device)\n",
    "        noisy_labels = noise_dset[1].long().to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = custom_model(noisy_inputs)\n",
    "\n",
    "        preds = torch.argmax(output,dim=1)\n",
    "        corrects += torch.sum(noisy_labels == preds)\n",
    "        totals += len(noisy_labels)\n",
    "\n",
    "        loss = criterion(output, noisy_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 5 ==0:\n",
    "        print(loss.item(), corrects/totals)\n",
    "    if corrects/totals>0.99 and epoch > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "northern-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects/totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-honolulu",
   "metadata": {},
   "source": [
    "# CMA Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "grateful-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = torch.load('alexnet_only_noise.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "supposed-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_attack = custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "executed-continuity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288616ca8aa44373be77c94772bfd233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_output = utils.cma_experiment_3d(model_to_attack, (1,3,32,32), test_limits, limits, 5, sigma_0 = 0.01,verb_disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-specification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
