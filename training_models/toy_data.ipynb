{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authentic-personal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesser-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributions as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "current-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cma\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "respective-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "floppy-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_uniform(batch_size, N_dim, r1, r2, image = False):\n",
    "    random_matrix = (r1 - r2) * torch.rand([batch_size, N_dim]) + r2\n",
    "    if image == False:\n",
    "        return random_matrix\n",
    "    else:\n",
    "        side_size = int(np.sqrt(int(N_dim/3)))\n",
    "        if side_size ** 2 != int(N_dim/3):\n",
    "            print('N_dim/3 must be perfect square in image mode.')\n",
    "            return -1\n",
    "        resized = random_matrix.reshape(batch_size, 3, side_size, side_size)\n",
    "        return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "toxic-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_mixture_model(N_dim, N_mix):\n",
    "    mix = D.Categorical(torch.rand(N_dim,N_mix))\n",
    "    comp = D.Independent(D.Normal(\n",
    "                torch.randn(N_dim,N_mix,1), torch.rand(N_dim,N_mix,1)), 1)\n",
    "\n",
    "    gmm = torch.distributions.mixture_same_family.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "advanced-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LeNet5(nn.Module):\n",
    "\n",
    "#     def __init__(self,data_dimensions, model_name):\n",
    "#         super(LeNet5, self).__init__()\n",
    "#         self.name = 'LeNet5_%s'%model_name\n",
    "#         self.dataset = None\n",
    "#         self.feature_extractor = nn.Sequential(            \n",
    "#             nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AvgPool2d(kernel_size=4),\n",
    "# #             nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.AvgPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=6, out_channels=60, kernel_size=7, stride=1),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(in_features=60, out_features=84),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(in_features=84, out_features=2),\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.feature_extractor(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         logits = self.classifier(x)\n",
    "# #         probs = F.softmax(logits, dim=1)\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "residential-spider",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6c6f56ccf5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         self.layers = nn.Sequential(\n\u001b[1;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dimensions\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, data_dimensions,name):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(data_dimensions, int(data_dimensions*5)),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(int(data_dimensions*5), int(data_dimensions/5)),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(int(data_dimensions*5), 2)\n",
    "        )\n",
    "        self.name = name\n",
    "        self.train_accuracy = 0\n",
    "        self.test_accuracy = 0\n",
    "        self.dataset = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "actual-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMA_info():\n",
    "    def __init__(self, model_name, num_samples):\n",
    "        super(CMA_info, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_samples = num_samples\n",
    "        \n",
    "        self.distances = []\n",
    "        self.in_dist_advs = []\n",
    "        self.advs = []\n",
    "        self.starts = []\n",
    "    \n",
    "    def summary(self):\n",
    "        print('****************** CMA Summary *******************')\n",
    "        print('Trained on %s points:'%self.model_name.split('_')[-1])\n",
    "        print('Adversarials: %s/%s'%(len(self.advs), self.num_samples))\n",
    "        print('In-distribution: %s/%s'%(len(self.in_dist_advs), len(self.advs)))\n",
    "        \n",
    "        avg_dist = np.mean(self.distances)\n",
    "        print('Average L2 distance: %s'%(avg_dist))\n",
    "        print('*'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dental-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min = -10\n",
    "x1_max = 10\n",
    "\n",
    "x2_min = 20\n",
    "x2_max = 40\n",
    "\n",
    "test_min = -1\n",
    "test_max= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "golden-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = get_random_mixture_model(N_dim, N_mix)\n",
    "# model_2 = get_random_mixture_model(N_dim, N_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "preceding-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_1 = model_1.sample(sample_shape=torch.Size([10000])).squeeze(2)\n",
    "# sample_2 = model_2.sample(sample_shape=torch.Size([10000])).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "actual-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dataset_size, image_data = False):\n",
    "    sample_1 = sample_uniform(dataset_size, N_dim, x1_min, x1_max, image_data)\n",
    "    sample_2 = sample_uniform(dataset_size, N_dim, x2_min, x2_max, image_data)\n",
    "    \n",
    "    labels_1 = torch.zeros(len(sample_1))\n",
    "    labels_2 = torch.ones(len(sample_2))\n",
    "    \n",
    "    X = torch.vstack([sample_1, sample_2])\n",
    "    Y = torch.hstack([labels_1, labels_2])\n",
    "    ids = list(range(len(X)))\n",
    "\n",
    "    random.shuffle(ids)\n",
    "    train_ids = ids[:int(0.8*len(X))]\n",
    "    test_ids = ids[int(0.8*len(X)):]\n",
    "\n",
    "    # len(X)\n",
    "\n",
    "    X_train = X[train_ids].cuda()\n",
    "    X_test = X[test_ids].cuda()\n",
    "\n",
    "    Y_train = Y[train_ids].cuda()\n",
    "    Y_test = Y[test_ids].cuda()\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "secure-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(N_dim, dataset, name, image_data = False):\n",
    "    X_train, X_test, Y_train, Y_test = dataset\n",
    "    \n",
    "    if image_data:\n",
    "        model = LeNet5(N_dim, name).cuda()\n",
    "    else:\n",
    "        model = MLP(N_dim, name).cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    model.dataset = dataset\n",
    "    \n",
    "    for epoch in tqdm(range(1000)): \n",
    "        outputs = model(X_train)\n",
    "        loss = loss_fn(outputs, Y_train.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = torch.argmax(model(X_test), dim=1)\n",
    "        accuracy = torch.sum(predictions == Y_test)/len(Y_test)\n",
    "        \n",
    "        train_predictions = torch.argmax(model(X_train), dim=1)\n",
    "        train_accuracy = torch.sum(train_predictions == Y_train)/len(Y_train)\n",
    "\n",
    "        if epoch == 999:\n",
    "            print(\"Epoch:%s, Train Acc:%s\"%(epoch, train_accuracy))\n",
    "            print(\"Epoch:%s, Test Acc:%s\"%(epoch, accuracy))\n",
    "        \n",
    "        model.test_accuracy = accuracy\n",
    "        model.train_accuracy = train_accuracy\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "magnetic-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tests for generating and training image models####\n",
    "\n",
    "# image_test_data = make_dataset(1000, True)\n",
    "# image_test_model = train_model(N_dim, image_test_data, 'dset_size_%s'%dsize, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-apache",
   "metadata": {},
   "source": [
    "# CMA failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "difficult-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cma_objective(x_input):\n",
    "#     torch_x = torch.from_numpy(x_input).unsqueeze(0).float()\n",
    "#     if 'LeNet' in CURRENT_MODEL.name\n",
    "#     output = CURRENT_MODEL(torch_x)\n",
    "#     pred_prob = output[0][CATEGORY_NUM].item()\n",
    "#     prediction = torch.argmax(output[0]).item()\n",
    "#     return pred_prob, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "phantom-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.vstack([start_pos[0].unsqueeze(0), start_pos[0].unsqueeze(0), start_pos[0].unsqueeze(0)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opened-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cma_objective(x_input):\n",
    "    try:\n",
    "        if 'LeNet' in CURRENT_MODEL.name:\n",
    "            side_size = int(np.sqrt(N_dim))\n",
    "            torch_x = torch.from_numpy(x_input).reshape(1,1,side_size,side_size).float()\n",
    "        else:\n",
    "            torch_x = torch.from_numpy(x_input).unsqueeze(0).float()\n",
    "    except:\n",
    "        side_size = int(np.sqrt(int(N_dim/3)))\n",
    "        torch_x_channel = torch.from_numpy(x_input).reshape(1,3,side_size,side_size).float()\n",
    "        torch_x = torch.vstack([torch_x_channel, torch_x_channel, torch_x_channel]).cuda()\n",
    "        \n",
    "    output = CURRENT_MODEL(torch_x)\n",
    "    pred_prob = output[0][CATEGORY_NUM].item()\n",
    "    prediction = torch.argmax(output[0]).item()\n",
    "    return pred_prob, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "renewable-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cma_experiment(attacked_model, num_samples = 50, image_data = False):\n",
    "    cma_search_output = {}\n",
    "    global CURRENT_MODEL\n",
    "    CURRENT_MODEL = attacked_model\n",
    "    try:\n",
    "        print(CURRENT_MODEL.name)\n",
    "        cma_output = CMA_info(CURRENT_MODEL.name, num_samples)\n",
    "    except:\n",
    "        print('ResNet')\n",
    "        cma_output = CMA_info('ResNet', num_samples)\n",
    "        \n",
    "    for i in tqdm(range(num_samples)):\n",
    "        initial_pred = 1\n",
    "        while initial_pred == 1:\n",
    "            start_pos = sample_uniform(3, N_dim, test_min, test_max, image_data).cuda()\n",
    "            output = CURRENT_MODEL(start_pos)\n",
    "            initial_pred = torch.argmax(output[0]).item()\n",
    "        cma_output.starts.append(start_pos)\n",
    "        if image_data:\n",
    "            start_pos = start_pos[0].reshape(1,-1)[0].cpu()\n",
    "#             start_pos = start_pos[0,0].reshape(1,-1)[0]\n",
    "\n",
    "        else:\n",
    "            start_pos = start_pos[0]\n",
    "        es = cma.CMAEvolutionStrategy(start_pos, 0.00005)\n",
    "        es.optimize(cma_objective, verb_disp = False, iterations=1500, correct_prediction = CATEGORY_NUM)\n",
    "        adv_offspring_ids = np.where(np.array(es.predictions) != 0)\n",
    "        \n",
    "        if len(adv_offspring_ids[0]) > 0:\n",
    "            random_adv_offspring_id = random.choice(list(adv_offspring_ids[0]))\n",
    "            random_adv_offspring = es.prediction_settings[random_adv_offspring_id]\n",
    "            cma_output.advs.append(random_adv_offspring)        \n",
    "\n",
    "            max_val = np.max(random_adv_offspring)\n",
    "            if max_val < x1_max:\n",
    "                cma_output.in_dist_advs.append(random_adv_offspring)\n",
    "                distance = np.linalg.norm(start_pos - random_adv_offspring)\n",
    "                cma_output.distances.append(distance)\n",
    "    return cma_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affected-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_NUM = 0\n",
    "CURRENT_MODEL = None\n",
    "\n",
    "N_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "comic-landscape",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Iteration 0\n",
      "**************************************************\n",
      "Working with with 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0807db764cae4bd28087e1d44dd8cbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999, Train Acc:tensor(0.9998, device='cuda:0')\n",
      "Epoch:999, Test Acc:tensor(0.9998, device='cuda:0')\n",
      "dset_size_10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a955902542ee49cf9134262be4722f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a56dbd5b52dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dset_size_%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel_to_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mattack_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdsize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcma_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_attack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0miter_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrained_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mall_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7eae036abe48>\u001b[0m in \u001b[0;36mcma_experiment\u001b[0;34m(attacked_model, num_samples, image_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0minitial_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mstart_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCURRENT_MODEL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0minitial_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcma_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-6c6f56ccf5fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/om5/user/smadan/miniconda3/envs/diff_rendering_ml/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)"
     ]
    }
   ],
   "source": [
    "all_info = []\n",
    "\n",
    "for iteration in range(1):\n",
    "    print('*'*50)\n",
    "    print('Iteration %s'%iteration)\n",
    "    print('*'*50)\n",
    "    \n",
    "    trained_models = {}\n",
    "    attack_output = {}\n",
    "    for dsize in [10000]:\n",
    "        print('Working with with %s'%dsize)\n",
    "        dset = make_dataset(dsize)\n",
    "        trained_models[dsize] = train_model(N_dim, dset, 'dset_size_%s'%dsize)\n",
    "        model_to_attack = trained_models[dsize].cpu()\n",
    "        attack_output[dsize] = cma_experiment(model_to_attack, 200)\n",
    "    iter_info = [trained_models, attack_output]\n",
    "    all_info.append(iter_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-forestry",
   "metadata": {},
   "source": [
    "# Nearest neighbor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "piano-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points = all_info[0][1][10000].starts\n",
    "in_dist_advs_points = all_info[0][1][10000].in_dist_advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "waiting-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_points = all_info[0][0][10000].dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "suspected-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_neighbor_distances = []\n",
    "for start_p in starting_points:\n",
    "    distances = torch.sum((training_points - start_p.cuda())**2, dim = 1)\n",
    "    neighbors = torch.argsort(distances)[:10].cpu()\n",
    "    neighbor_distance = torch.sum(distances[neighbors]).item()\n",
    "    start_neighbor_distances.append(neighbor_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "irish-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_neighbor_distances = []\n",
    "for adv_p in in_dist_advs_points:\n",
    "    distances = torch.sum((training_points - torch.from_numpy(adv_p).cuda())**2, dim = 1)\n",
    "    neighbors = torch.argsort(distances)[:10].cpu()\n",
    "    neighbor_distance = torch.sum(distances[neighbors]).item()\n",
    "    adv_neighbor_distances.append(neighbor_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "czech-sterling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6., 14., 27., 34., 36., 35., 28., 12.,  7.,  1.]),\n",
       " array([ 9783.97070312,  9829.94902344,  9875.92734375,  9921.90566406,\n",
       "         9967.88398437, 10013.86230469, 10059.840625  , 10105.81894531,\n",
       "        10151.79726563, 10197.77558594, 10243.75390625]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPt0lEQVR4nO3de6ykdX3H8fdHwFvVssiRbrh0qdJaYsoixy2t1gtWBPljsbWNpNFNJVlrNQGjjas2raY1WVovSVNjswp1TRRFxUDF20ppqVHAs3aFBeTqGqErexQpkiZY8Ns/5lmZHs7szDln5sz+8P1KJvPM7/nNPN/nd+Z8zjPPZU6qCklSex437QIkSctjgEtSowxwSWqUAS5JjTLAJalRh67mwo488shat27dai5Skpq3c+fOH1bVzML2VQ3wdevWMTc3t5qLlKTmJfneYu3uQpGkRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEat6pWY0jDrtlwxleXu2XrWVJYrrYRb4JLUqKEBnuSJSa5L8u0kNyZ5d9f+0STfTbKru62feLWSpJ8bZRfKg8BpVfVAksOAryX5YjfvL6rqM5MrT5I0yNAAr95/PX6ge3hYd/M/IUvSlI10EDPJIcBO4FnAB6vq2iRvAN6T5K+AK4EtVfXgIs/dDGwGOO6448ZWuDRO0zp4Ch5A1fKNdBCzqh6uqvXAMcCGJM8B3g48G3gecATwtgHP3VZVs1U1OzPzqO8jlyQt05LOQqmq+4CrgDOqam/1PAj8M7BhAvVJkgYY5SyUmSSHd9NPAl4GfCfJ2q4twNnA7smVKUlaaJR94GuB7d1+8McBl1TV55P8a5IZIMAu4M8mV6YkaaFRzkK5Hjh5kfbTJlKRJGkkXkqvR5nmGRmSRuel9JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjhgZ4kicmuS7Jt5PcmOTdXfvxSa5NcnuSTyV5/OTLlSTtN8oW+IPAaVV1ErAeOCPJqcAFwAeq6lnAj4FzJ1alJOlRhgZ49TzQPTysuxVwGvCZrn07cPYkCpQkLW6kfeBJDkmyC9gH7ADuAO6rqoe6LncBRw947uYkc0nm5ufnx1CyJAlGDPCqeriq1gPHABuAZ4+6gKraVlWzVTU7MzOzvColSY+ypLNQquo+4Crgd4DDkxzazToGuHu8pUmSDmSUs1BmkhzeTT8JeBlwM70gf1XXbRNw2YRqlCQt4tDhXVgLbE9yCL3Av6SqPp/kJuCTSf4W+E/gwgnWKUlaYGiAV9X1wMmLtN9Jb3+4JGkKvBJTkhplgEtSowxwSWqUAS5JjTLAJalRBrgkNWqU88AlTdC6LVdMZbl7tp41leVqfNwCl6RGGeCS1CgDXJIaZYBLUqM8iHkQm9bBLUltcAtckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KihAZ7k2CRXJbkpyY1Jzuva35Xk7iS7utsrJl+uJGm/Ua7EfAh4S1V9K8lTgZ1JdnTzPlBV751ceZKkQYYGeFXtBfZ20z9JcjNw9KQLkyQd2JL2gSdZB5wMXNs1vSnJ9UkuSrJmwHM2J5lLMjc/P7+yaiVJPzdygCd5CvBZ4Pyquh/4EPBMYD29LfT3Lfa8qtpWVbNVNTszM7PyiiVJwIgBnuQweuH98aq6FKCq7qmqh6vqZ8CHgQ2TK1OStNAoZ6EEuBC4uare39e+tq/bK4Hd4y9PkjTIKGehPB94DXBDkl1d2zuAc5KsBwrYA7x+AvVJkgYY5SyUrwFZZNYXxl+OJGlUXokpSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGDQ3wJMcmuSrJTUluTHJe135Ekh1Jbuvu10y+XEnSfqNsgT8EvKWqTgROBd6Y5ERgC3BlVZ0AXNk9liStkqEBXlV7q+pb3fRPgJuBo4GNwPau23bg7AnVKElaxJL2gSdZB5wMXAscVVV7u1k/AI4a8JzNSeaSzM3Pz6+kVklSn5EDPMlTgM8C51fV/f3zqqqAWux5VbWtqmaranZmZmZFxUqSHjFSgCc5jF54f7yqLu2a70mytpu/Ftg3mRIlSYsZ5SyUABcCN1fV+/tmXQ5s6qY3AZeNvzxJ0iCHjtDn+cBrgBuS7Ora3gFsBS5Jci7wPeCPJ1KhJGlRQwO8qr4GZMDsl463HEnSqLwSU5IaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWrUKP+V/qIk+5Ls7mt7V5K7k+zqbq+YbJmSpIVG2QL/KHDGIu0fqKr13e0L4y1LkjTM0ACvqquBe1ehFknSEqxkH/ibklzf7WJZM7aKJEkjWW6Afwh4JrAe2Au8b1DHJJuTzCWZm5+fX+biJEkLLSvAq+qeqnq4qn4GfBjYcIC+26pqtqpmZ2ZmllunJGmBZQV4krV9D18J7B7UV5I0GYcO65DkYuDFwJFJ7gL+GnhxkvVAAXuA10+uREnSYoYGeFWds0jzhROoRZK0BEMDXLBuyxXTLkGSHsVL6SWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEb5XSjSL6hpfsfPnq1nTW3ZjyVugUtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1KihAZ7koiT7kuzuazsiyY4kt3X3ayZbpiRpoVG2wD8KnLGgbQtwZVWdAFzZPZYkraKhAV5VVwP3LmjeCGzvprcDZ4+3LEnSMMvdB35UVe3tpn8AHDWoY5LNSeaSzM3Pzy9zcZKkhVZ8ELOqCqgDzN9WVbNVNTszM7PSxUmSOssN8HuSrAXo7veNryRJ0iiWG+CXA5u66U3AZeMpR5I0qlFOI7wY+AbwG0nuSnIusBV4WZLbgN/vHkuSVtHQ7wOvqnMGzHrpmGuRJC2BV2JKUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVFDv8xKksZt3ZYrprLcPVvPmspyJ8UtcElqlAEuSY0ywCWpUQa4JDWqmYOY0zroIUkHK7fAJalRBrgkNWpFu1CS7AF+AjwMPFRVs+MoSpI03Dj2gb+kqn44hteRJC2Bu1AkqVErDfACvpJkZ5LNi3VIsjnJXJK5+fn5FS5OkrTfSgP8BVX1XOBM4I1JXriwQ1Vtq6rZqpqdmZlZ4eIkSfutKMCr6u7ufh/wOWDDOIqSJA237ABP8ktJnrp/Gjgd2D2uwiRJB7aSs1COAj6XZP/rfKKqvjSWqiRJQy07wKvqTuCkMdYiSVoCTyOUpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRq3kX6pJUlPWbbliasves/Wssb+mW+CS1CgDXJIataIAT3JGkluS3J5ky7iKkiQNt+wAT3II8EHgTOBE4JwkJ46rMEnSga1kC3wDcHtV3VlVPwU+CWwcT1mSpGFWchbK0cD3+x7fBfz2wk5JNgObu4cPJLllBcsc1ZHAD1dhOQc7x6HHcehxHB6x6mORC1b09F9drHHipxFW1TZg26SX0y/JXFXNruYyD0aOQ4/j0OM4POKxMhYr2YVyN3Bs3+NjujZJ0ipYSYB/EzghyfFJHg+8Grh8PGVJkoZZ9i6UqnooyZuALwOHABdV1Y1jq2xlVnWXzUHMcehxHHoch0c8JsYiVTXtGiRJy+CVmJLUKANckhrVTIAnOS/J7iQ3Jjm/a1uf5Joku5LMJdnQtSfJP3SX+F+f5Ll9r7MpyW3dbdOUVmfZBozDSUm+keSGJP+S5Gl9/d/ejcMtSV7e197c1yAkuSjJviS7+9qOSLKj+3nuSLKma1/yeyDJKd0Y3t49N6u7hqNZ4jg8u3tvPJjkrQteZ9H3QHdiwrVd+6e6kxQOOkschz/p3gc3JPl6kpP6ntPuOFTVQX8DngPsBp5M78DrV4FnAV8Bzuz6vAL4t77pLwIBTgWu7dqPAO7s7td002umvX5jGIdvAi/q+rwO+Jtu+kTg28ATgOOBO+gdcD6km/414PFdnxOnvX4jrP8LgecCu/va/g7Y0k1vAS5Y7nsAuK7rm+65Z057nccwDs8Ange8B3hrX/+B7wHgEuDV3fQ/AW+Y9jqPYRx+t+/nfGbf+6HpcWhlC/w36Q34/1TVQ8C/A38AFLB/a/OXgf/qpjcCH6uea4DDk6wFXg7sqKp7q+rHwA7gjNVckRUaNA6/Dlzd9dkB/GE3vRH4ZFU9WFXfBW6n9xUITX4NQlVdDdy7oHkjsL2b3g6c3dc+8nugm/e0qrqmer+xH+t7rYPKUsahqvZV1TeB/13Qf9H3QPep4zTgMwtf62CzxHH4evfzBriG3nUr0Pg4tBLgu4HfS/L0JE+mt3V1LHA+8PdJvg+8F3h713+xy/yPPkB7KwaNw408EsB/xCMXWD1Wx6HfUVW1t5v+AXBUN73UdT+6m17Y3opB4zDIoHF4OnBft4HQ396KUcbhXHqfsKDxcWgiwKvqZuACertMvgTsAh4G3gC8uaqOBd4MXDitGlfDAcbhdcCfJ9kJPBX46bRqnKZuy/kX/rxYx6FnsXFI8hJ6Af62qRQ1Zk0EOEBVXVhVp1TVC4EfA7cCm4BLuy6fpvdxCAZf5t/85f+LjUNVfaeqTq+qU4CL6e3Tg8fwOPS5p9v9QXe/r2tf6rrfzSMfq/vbWzFoHAYZNA4/ore76dAF7a0YOA5Jfgv4CLCxqn7UNTc9Ds0EeJJndPfH0dvv+wl6+7xf1HU5Dbitm74ceG13JsKpwH93H6u+DJyeZE13dPr0rq0Zi41DX9vjgL+kd8AFeuPw6iRPSHI8cAK9A3WPpa9BuJzeH3K6+8v62kd+D3Tz7k9yarf/87V9r9WCQeMwyKLvgW6r9SrgVUt4rYPJouPQ/b5cCrymqm7t69/2OEz7KOqoN+A/gJvoHSV+adf2AmBn13YtcErXHnr/bOIO4AZgtu91XkfvYN7twJ9Oe73GNA7n0ftEciuwle4K227eO7txuIW+syro7T+/tZv3zmmv14jrfjGwl94BubvofRR+OnAlvT/eXwWOWO57AJild5zhDuAf+8fxYLotcRx+petzP3BfN/20A70H6J2RcV03Pp8GnjDtdR7DOHyE3ifWXd1tbtjvQgvj4KX0ktSoZnahSJL+PwNckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNer/AEC3pehmbCXWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(start_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "foreign-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1., 14., 24., 35., 57., 27., 24., 13.,  3.]),\n",
       " array([ 9745.3152557 ,  9786.44640246,  9827.57754922,  9868.70869598,\n",
       "         9909.83984275,  9950.97098951,  9992.10213627, 10033.23328303,\n",
       "        10074.36442979, 10115.49557655, 10156.62672331]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(adv_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "yellow-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9968.880871738756"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(adv_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "marine-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9993.585009765626"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(start_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "coated-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.24857643062266"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(adv_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "confirmed-rabbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.18667565876925"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(start_neighbor_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "embedded-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('info_iters.p','rb') as F:\n",
    "#     all_info = pickle.load(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-leone",
   "metadata": {},
   "source": [
    "# Adversarial Training analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-reynolds",
   "metadata": {},
   "source": [
    "### Collect adv points (25% of training data size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "casual-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_output_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "former-winter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dset_size_10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bc90d8466d49cca92ac278ceb321a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attack_output_2[dsize] = cma_experiment(model_to_attack, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "specified-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('inof.p', 'wb') as F:\n",
    "#     pickle.dump(attack_output_2, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "coated-retro",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "augmented_training_data = torch.vstack([training_points, torch.tensor(attack_output_2[dsize].in_dist_advs).float().cuda()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-finance",
   "metadata": {},
   "source": [
    "### Train with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "assigned-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = dset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "controlling-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_training_labels = torch.hstack([training_labels, torch.zeros(4000).long().cuda()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "southern-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented_training_labels[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "institutional-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_new = [augmented_training_data, dset[1], augmented_training_labels, dset[3]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "similar-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_trained_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "furnished-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_attack_output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "minus-split",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d292af428f1846458c1fb9a9fa88716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:999, Train Acc:tensor(1., device='cuda:0')\n",
      "Epoch:999, Test Acc:tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# dset = make_dataset(dsize)\n",
    "adv_trained_models[dsize] = train_model(N_dim, dset_new, 'dset_size_%s_adv'%dsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dedicated-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_trained_models[10000].dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "double-yesterday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dset_size_10000_adv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df79fac3a3448ab9cbb50045058d882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv_model_to_attack = adv_trained_models[dsize].cpu()\n",
    "adv_attack_output[dsize] = cma_experiment(adv_model_to_attack, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "familiar-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(adv_attack_output[dsize].in_dist_advs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-muscle",
   "metadata": {},
   "source": [
    "# Training Image Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "palestinian-artwork",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dset = make_dataset(dsize, image_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "younger-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_uniform(100, N_dim, x1_min, x1_max, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "worldwide-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16000, 3, 15, 15])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "loving-charge",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all_info = []\n",
    "\n",
    "# for iteration in range(10):\n",
    "#     print('*'*50)\n",
    "#     print('Iteration %s'%iteration)\n",
    "#     print('*'*50)\n",
    "    \n",
    "#     trained_models = {}\n",
    "#     attack_output = {}\n",
    "#     for dsize in [10000]:\n",
    "#         print('Working with with %s'%dsize)\n",
    "#         dset = make_dataset(dsize, image_data=True)\n",
    "#         trained_models[dsize] = train_model(N_dim, dset, 'dset_size_%s'%dsize, image_data=True)\n",
    "#         model_to_attack = trained_models[dsize].cpu()\n",
    "#         attack_output[dsize] = cma_experiment(model_to_attack, 10, image_data=True)\n",
    "#     iter_info = [trained_models, attack_output]\n",
    "#     all_info.append(iter_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "modern-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('all_info_lenet.p','wb') as F:\n",
    "#     pickle.dump(all_info, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-winning",
   "metadata": {},
   "source": [
    "# Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "resnet_model = torchvision.models.resnet18(num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "numerous-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = make_dataset(dsize, image_data=True)\n",
    "\n",
    "# trained_models[dsize] = train_model(N_dim, dset, 'dset_size_%s'%dsize, image_data=True)\n",
    "# model_to_attack = trained_models[dsize].cpu()\n",
    "# attack_output[dsize] = cma_experiment(model_to_attack, 10, image_data=True)\n",
    "# iter_info = [trained_models, attack_output]\n",
    "# all_info.append(iter_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "imposed-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = torchvision.models.resnet18(num_classes = 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "better-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "textile-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_dataset = {}\n",
    "resnet_dataset['train'] = dset[0]\n",
    "resnet_dataset['test'] = dset[1]\n",
    "\n",
    "resnet_labels= {}\n",
    "resnet_labels['train'] = dset[2]\n",
    "resnet_labels['test'] = dset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cubic-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "biological-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "undefined-truck",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9c6e02bb204ab3890ce37a2032834d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.91625\n",
      "test accuracy: 0.95775\n",
      "train accuracy: 0.9983125\n",
      "test accuracy: 1.0\n",
      "train accuracy: 0.99975\n",
      "test accuracy: 1.0\n",
      "train accuracy: 1.0\n",
      "test accuracy: 1.0\n",
      "train accuracy: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-9c460ef55507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0miter_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mbatch_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0miter_corrects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    for phase in ['train', 'test']:\n",
    "        X = resnet_dataset[phase]\n",
    "        Y = resnet_labels[phase]\n",
    "        iters = int(X.shape[0]/batch_size)\n",
    "        batch_corrects = 0\n",
    "        for i in range(iters):\n",
    "            batch_data = X[batch_size*i:batch_size*(i+1)].float()            \n",
    "            batch_labels = Y[batch_size*i:batch_size*(i+1)].long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_model(batch_data)           \n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            iter_corrects = torch.sum(torch.argmax(outputs, dim = 1) == batch_labels).item()\n",
    "            batch_corrects += iter_corrects\n",
    "        if epoch % 5 == 0:\n",
    "            print('%s accuracy: %s'%(phase, batch_corrects/len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "young-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_model, 'resnet_uniform_data_20_epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "aerial-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_to_attack = resnet_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "facial-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_attack_output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "driving-token",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15, 15])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pos[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "important-omega",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([675])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pos[0].reshape(1,-1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "rental-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.sum(start_pos[0].reshape(1,-1)[0].reshape(3,15,15) == start_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "stone-symbol",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "encouraging-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_MODEL = CURRENT_MODEL.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-imagination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ecfa34b3044acaf5be4c64b04207a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet_attack_output[dsize] = cma_experiment(resnet_model_to_attack, 50, image_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet_attack_output.p', 'wb') as F:\n",
    "    pickle.dump(resnet_attack_output, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-amplifier",
   "metadata": {},
   "source": [
    "# Aggregate evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "committed-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = {}\n",
    "in_dists = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "portuguese-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_info[0][1][dsize].in_dist_advs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "diagnostic-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dsize in [1000, 100000]:\n",
    "    all_distances[dsize] = []\n",
    "    in_dists[dsize] = []\n",
    "    for i in range(1):\n",
    "        in_dists[dsize].append(len(all_info[i][1][dsize].in_dist_advs))\n",
    "        all_distances[dsize].append(np.nanmean(all_info[i][1][dsize].distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "congressional-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_distances.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "entitled-bridges",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2171293443927995\n",
      "5.13962748088732\n"
     ]
    }
   ],
   "source": [
    "for key in all_distances.keys():\n",
    "    print(np.nanmean(all_distances[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "destroyed-airfare",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "for key in in_dists.keys():\n",
    "    print(np.mean(in_dists[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "comparable-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, point):\n",
    "    prepped_point = torch.from_numpy(point).cuda().float().unsqueeze(0)\n",
    "    prediction = torch.argmax(model(prepped_point)[0]).item()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-pasta",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "indie-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = make_dataset(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "welcome-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, X_test, _, Y_test = dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "complicated-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "automated-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(all_info[0][0][1000],'test_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "sticky-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch2keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "diagnostic-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "# a# from keras.models import load_model\n",
    "\n",
    "# pytorch_model = 'test_model.pt'\n",
    "# keras_output = 'test_model_keras.hd5'\n",
    "# onnx.convert(pytorch_model, keras_output)\n",
    "# # \n",
    "# # preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "reduced-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras_model = load_model(keras_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "forbidden-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value=1.5\n",
    "# width=0.75\n",
    "# features_to_plot = [0,1]\n",
    "# filler_values = {}\n",
    "# filler_ranges = {}\n",
    "# for i in range(N_dim):\n",
    "#     if i not in features_to_plot:\n",
    "#         filler_values[i] = value\n",
    "#         filler_ranges[i] = width\n",
    "\n",
    "\n",
    "# plot_decision_regions(X_test.cpu().numpy(), Y_test.cpu().numpy().astype('int'), \n",
    "#                       clf=all_info[0][0][1000], legend = 2, feature_index=[0,1],                        #these one will be plotted  \n",
    "#                   filler_feature_values=filler_values,  #these will be ignored\n",
    "#                   filler_feature_ranges=filler_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-guest",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "imperial-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "foreign-pepper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = all_info[0][0][DSIZE].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "scenic-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_subset(start, adv, mod, start_id = 0):\n",
    "    for i in range(start_id, start_id + 50):\n",
    "        index = i%50\n",
    "        start[:index] = adv[:index]\n",
    "        start_pred = predict(mod, start)\n",
    "        adv_pred = predict(mod, adv)\n",
    "        if start_pred == adv_pred:\n",
    "            break\n",
    "    return index        \n",
    "#     print('Broke at %i'%index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "growing-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_changes = []\n",
    "for i in range(10):\n",
    "    adv_point = all_info[0][1][DSIZE].in_dist_advs[i]\n",
    "    start_point = all_info[0][1][DSIZE].starts[i]\n",
    "    start_point = np.array(start_point)[0]\n",
    "    broken_change = min_subset(start_point, adv_point, mod, random.choice(list(range(50))))\n",
    "    broken_changes.append(broken_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "graduate-grounds",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.1\n",
      "6.057227088363123\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(broken_changes))\n",
    "print(np.std(broken_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-radar",
   "metadata": {},
   "source": [
    "# Opposite change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "intended-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('info_iters.p','rb') as F:\n",
    "    all_info = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "specialized-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_subset_reform(start, adv, mod, start_id = 0):\n",
    "    for i in range(start_id, start_id + 50):\n",
    "        index = i%50\n",
    "        adv[:index] = start[:index]\n",
    "        start_pred = predict(mod, start)\n",
    "        adv_pred = predict(mod, adv)\n",
    "        if start_pred == adv_pred:\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "copyrighted-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_changes = []\n",
    "for i in range(50):\n",
    "    adv_point = all_info[0][1][DSIZE].in_dist_advs[i]\n",
    "    start_point = all_info[0][1][DSIZE].starts[i]\n",
    "    start_point = np.array(start_point)[0]\n",
    "    broken_change = min_subset_reform(start_point, adv_point, mod, random.choice(list(range(50))))\n",
    "    broken_changes.append(broken_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "referenced-spice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.18\n",
      "13.122027282398097\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(broken_changes))\n",
    "print(np.std(broken_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-walker",
   "metadata": {},
   "source": [
    "# Random Perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "inclusive-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('info_iters.p','rb') as F:\n",
    "    all_info = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "filled-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_subset_random(start, adv, mod, start_id = 0):\n",
    "    for i in range(start_id, start_id + 50):\n",
    "        index = i%50\n",
    "        start[index] = np.random.normal(loc=np.mean(start[index]),scale=np.std(start[index]))\n",
    "        start_pred = predict(mod, start)\n",
    "        adv_pred = predict(mod, adv)\n",
    "        if start_pred == adv_pred:\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "burning-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "broken_changes = []\n",
    "for i in range(50):\n",
    "    adv_point = all_info[0][1][DSIZE].in_dist_advs[i]\n",
    "    start_point = all_info[0][1][DSIZE].starts[i]\n",
    "    start_point = np.array(start_point)[0]\n",
    "    broken_change = min_subset_random(start_point, adv_point, mod, random.choice(list(range(50))))\n",
    "    broken_changes.append(broken_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "reverse-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.98\n",
      "12.657788116412757\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(broken_changes))\n",
    "print(np.std(broken_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-collect",
   "metadata": {},
   "source": [
    "# Church Window Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "indian-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpendicular_vector(v):\n",
    "    random_vector = np.random.randn(N_dim)\n",
    "    orthogonal = random_vector - random_vector.dot(v)*v/np.linalg.norm(v)**2\n",
    "    orthogonal_normalized = orthogonal/np.linalg.norm(orthogonal) * np.linalg.norm(v)\n",
    "    return orthogonal_normalized\n",
    "\n",
    "def plot_church_window(start_point, adv_point):\n",
    "    adv_vector = adv_point - start_point\n",
    "#     adv_vector = np.random.randn(N_dim)*2.5\n",
    "    orthogonal_vector = perpendicular_vector(adv_vector)\n",
    "\n",
    "\n",
    "    ##### Collect Predictions ######\n",
    "    predictions = np.zeros((40,40))\n",
    "\n",
    "    row_num = 0\n",
    "    col_num = 0\n",
    "\n",
    "    for alpha in np.arange(0, 2.0, 0.05):\n",
    "        for beta in np.arange(0, 2.0, 0.05):\n",
    "            curr_point = start_point + beta*adv_vector + alpha*orthogonal_vector\n",
    "            curr_pred = predict(model, curr_point)\n",
    "            predictions[row_num][col_num] = curr_pred\n",
    "            col_num += 1\n",
    "        row_num += 1\n",
    "        col_num = 0\n",
    "\n",
    "    ##### Plot ######\n",
    "    plt.imshow(predictions, cmap=custom_cmap)\n",
    "    plt.xlim([0, 40])\n",
    "    plt.ylim([0, 40])\n",
    "    plt.title('Church Window Plot')\n",
    "    plt.xticks(range(0,40,5), labels = np.arange(0,2,0.25))\n",
    "    plt.yticks(range(0,40,5), labels = np.arange(0,2,0.25))\n",
    "    plt.xlabel('Adversarial Direction')\n",
    "    plt.ylabel('Orthogonal Direction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sixth-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "DSIZE = 1000\n",
    "N_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eleven-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('info_iters.p','rb') as F:\n",
    "    all_info = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adaptive-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_info[0][1][DSIZE].in_dist_advs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "obvious-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "derived-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "custom_cmap = colors.ListedColormap(['white', 'red'])\n",
    "bounds=[0,1]\n",
    "norm = colors.BoundaryNorm(bounds, custom_cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "careful-kingdom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1024,) and (50,) not aligned: 1024 (dim 0) != 50 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5a4e97a6bcb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDSIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplot_church_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-62fa86f7fa74>\u001b[0m in \u001b[0;36mplot_church_window\u001b[0;34m(start_point, adv_point)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0madv_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madv_point\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     adv_vector = np.random.randn(N_dim)*2.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0morthogonal_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperpendicular_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-62fa86f7fa74>\u001b[0m in \u001b[0;36mperpendicular_vector\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperpendicular_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrandom_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0morthogonal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_vector\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrandom_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0morthogonal_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morthogonal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morthogonal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0morthogonal_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1024,) and (50,) not aligned: 1024 (dim 0) != 50 (dim 0)"
     ]
    }
   ],
   "source": [
    "model = all_info[0][0][DSIZE].cuda()\n",
    "\n",
    "for i in range(10):\n",
    "    adv_point = all_info[0][1][DSIZE].in_dist_advs[i]\n",
    "    start_point = all_info[0][1][DSIZE].starts[i]\n",
    "    start_point = np.array(start_point)[0]\n",
    "    plot_church_window(start_point, adv_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-spectrum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
