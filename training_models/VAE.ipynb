{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "# from torchvision import datasets, models, transforms\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('/om5/user/smadan/training_scaffold_own/res/')\n",
    "from models.models import get_model\n",
    "from loader.loader import get_loader\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/om5/user/smadan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate parameters\n",
    "BASE_LR = 0.001\n",
    "EPOCH_DECAY = 30 # number of epochs after which the Learning rate is decayed exponentially.\n",
    "DECAY_WEIGHT = 0.1 # factor by which the learning rate is reduced.\n",
    "\n",
    "# DATASET INFO\n",
    "NUM_CLASSES = 2 # set the number of classes in your dataset\n",
    "DATA_DIR = '../data/' # to run with the sample dataset, just set to 'hymenoptera_data'\n",
    "\n",
    "# DATALOADER PROPERTIES\n",
    "BATCH_SIZE = 10 # Set as high as possible. If you keep it too high, you'll get an out of memory error.\n",
    "\n",
    "\n",
    "### GPU SETTINGS\n",
    "CUDA_DEVICE = 0 # Enter device ID of your gpu if you want to run on gpu. Otherwise neglect.\n",
    "GPU_MODE = 1 # set to 1 if want to run on gpu.\n",
    "\n",
    "MODEL_ARCH = 'simple_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_loader('multi_attribute_loader_file_list_shapenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'mnist_rotation_eight_by_nine'\n",
    "DATASET_NAME = 'shapenet_hand_picked'\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 10\n",
    "# ARCH = 'RESNET1'\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "GPU = 1\n",
    "\n",
    "# NUM_CLASSES = (10,10,10,10)\n",
    "NUM_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_model(ARCH,NUM_CLASSES)\n",
    "# loader_new = get_loader('multi_attribute_loader_file_list_mnist_rotation')\n",
    "loader_new = get_loader('multi_attribute_loader_file_list_shapenet')\n",
    "file_list_root = '/om5/user/smadan/dataset_lists_openmind'\n",
    "#att_path = '/data/graphics/toyota-pytorch/biased_dataset_generalization/dataset_lists/merged_colors_binned_attribute.p'\n",
    "att_path = '/om5/user/smadan/differentiable_graphics_ml/training_models/shapenet_id_to_class_num.p'\n",
    "shuffles = {'train':True,'val':True,'test':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = GPU_MODE\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(CUDA_DEVICE)\n",
    "\n",
    "count=0\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# data_dir = DATA_DIR\n",
    "# dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "#          for x in ['train', 'test']}\n",
    "# dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=BATCH_SIZE,\n",
    "#                                                shuffle=True, num_workers=25)\n",
    "#                 for x in ['train', 'test']}\n",
    "# dset_sizes = {x: len(dsets[x]) for x in ['train', 'test']}\n",
    "# dset_classes = dsets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ GET FROM USER CONFIG - TODO #####################\n",
    "file_lists = {}\n",
    "dsets = {}\n",
    "dset_loaders = {}\n",
    "dset_sizes = {}\n",
    "for phase in ['train','test']:\n",
    "    file_lists[phase] = \"%s/%s_list_%s.txt\"%(file_list_root,phase,DATASET_NAME)\n",
    "    dsets[phase] = loader_new(file_lists[phase],att_path, image_transform)\n",
    "    dset_loaders[phase] = torch.utils.data.DataLoader(dsets[phase], batch_size=BATCH_SIZE, shuffle = shuffles[phase], num_workers=2,drop_last=True)\n",
    "    dset_sizes[phase] = len(dsets[phase])\n",
    "\n",
    "\n",
    "# In[37]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
