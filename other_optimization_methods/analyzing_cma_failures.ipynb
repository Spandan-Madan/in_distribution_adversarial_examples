{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "existing-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/__init__.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/__init__.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader/multi_attribute_loader.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader/loader.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../inverse_rendering/')\n",
    "machine_path = os.getcwd()\n",
    "user_root_dir = '/'.join(machine_path.split('/')[:-2])\n",
    "sys.path.insert(0,'%s/redner/'%user_root_dir)\n",
    "import redner\n",
    "import pyredner\n",
    "print(pyredner.__file__)\n",
    "pyredner.render_pytorch.print_timing = False\n",
    "from general_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../training_models/shapenet_class_num_to_class_name.p','rb') as F:\n",
    "    shapenet_class_num_to_class_name = pickle.load(F)\n",
    "with open('../training_models/shapenet_id_to_class_num.p','rb') as F:\n",
    "    shapenet_id_to_class_num = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaging-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airplane,aeroplane,plane',\n",
       " 1: 'bed',\n",
       " 2: 'car,auto,automobile,machine,motorcar',\n",
       " 3: 'chair',\n",
       " 4: 'guitar',\n",
       " 5: 'knife',\n",
       " 6: 'motorcycle,bike',\n",
       " 7: 'piano,pianoforte,forte-piano',\n",
       " 8: 'pistol,handgun,side arm,shooting iron',\n",
       " 9: 'sofa,couch,lounge',\n",
       " 10: 'table'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapenet_class_num_to_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../training_models/saved_models/resnet18_v7_normalized_final.'\n",
    "loaded_model = torch.load(model_path)\n",
    "softmax_layer = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "catholic-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_scene_params(scene_params):\n",
    "    original_scene_params = [0,0,0,0]\n",
    "    original_scene_params[0] = scene_params[0]\n",
    "\n",
    "    original_scene_params[1] = {}\n",
    "    for key in scene_params[1].keys():\n",
    "        original_scene_params[1][key] = scene_params[1][key].clone()\n",
    "\n",
    "    original_scene_params[2] = {}\n",
    "    for key in scene_params[2].keys():\n",
    "        original_scene_params[2][key] = [i.clone() for i in scene_params[2][key]]\n",
    "\n",
    "    original_scene_params[3] = scene_params[3]\n",
    "    return original_scene_params\n",
    "\n",
    "def start_up(scene_params, optimized_params):\n",
    "    model_file, camera_params, light_params, material_settings = scene_params\n",
    "    variables = []\n",
    "    var_names_list = []\n",
    "    for param in optimized_params:\n",
    "        if param in camera_params.keys():\n",
    "            optimize_flags(camera_params[param])\n",
    "            if type(camera_params[param]) == list:\n",
    "                variables.extend(camera_params[param])\n",
    "            else:\n",
    "                variables.append(camera_params[param])\n",
    "        elif param in light_params.keys():\n",
    "            optimize_flags(light_params[param])\n",
    "            if type(light_params[param]) == list:\n",
    "                variables.extend(light_params[param])\n",
    "            else:\n",
    "                variables.append(light_params[param])\n",
    "\n",
    "    scene_params = [model_file, camera_params, light_params, material_settings]\n",
    "    scene = setup_scene(scene_params)\n",
    "\n",
    "    return scene, variables\n",
    "\n",
    "def load_geometry(model_file, geometry, mat):\n",
    "    if geometry:\n",
    "        obj_model_all = model_file\n",
    "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "    else:\n",
    "        obj_model_all = pyredner.load_obj(model_file, return_objects=True)\n",
    "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "\n",
    "    for part in obj_model:\n",
    "        part.material = mat\n",
    "\n",
    "    return obj_model\n",
    "\n",
    "def render_input(scene):\n",
    "    img = pyredner.render_pathtracing(scene = scene, num_samples = 512, seed = 1)\n",
    "    img = torch.clamp(img, min = 0.00000001)\n",
    "    img = torch.pow(img, 1.0/2.2)\n",
    "    img = img*255/torch.max(img)\n",
    "    inputs = img.permute(2,0,1).unsqueeze(0)\n",
    "    return inputs, img\n",
    "\n",
    "def setup_scene(scene_params):\n",
    "\n",
    "    model_file, camera_params, light_params, material_settings = scene_params\n",
    "    obj_model = load_geometry(model_file, False, material_settings['diffuse_material'])\n",
    "\n",
    "    #### Camera Setup ####\n",
    "    scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224),\n",
    "                                                   fov = torch.tensor([camera_params['fov']]),\n",
    "                                                   up = camera_params['cam_up'],\n",
    "                                                   look_at = camera_params['cam_look_at'])\n",
    "    scene_cam.position = camera_params['camera_position']\n",
    "\n",
    "    #### Lights Setup ####\n",
    "    scene_lights = []\n",
    "    num_lights = len(light_params['all_light_positions'])\n",
    "    for i in range(num_lights):\n",
    "        scene_light = pyredner.generate_quad_light(position = light_params['all_light_positions'][i],\n",
    "                                     look_at = light_params['all_light_look_ats'][i],\n",
    "                                     size = light_params['all_light_sizes'][i],\n",
    "                                     intensity = light_params['all_light_intensities'][i],\n",
    "                                     directly_visible = False)\n",
    "        scene_lights.append(scene_light)\n",
    "\n",
    "    all_objects = obj_model + scene_lights\n",
    "    scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
    "\n",
    "    return scene\n",
    "\n",
    "def show_inputs(inp, save_path = False, title='No Title'):\n",
    "    plt.imshow(inp[0].cpu().permute(1,2,0).int())\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    if save_path != False:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breeding-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = os.listdir(folder)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frequent-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_camera = False\n",
    "varying_light = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expanded-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_exp(exp_path, save_folder):\n",
    "    with open(exp_path, 'rb') as F:\n",
    "        exp_info = pickle.load(F)\n",
    "\n",
    "    starting_scene_params = exp_info['scene_params']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "national-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_exp(exp_path, render = False, show = False):\n",
    "    with open(exp_path, 'rb') as F:\n",
    "        exp_info = pickle.load(F)\n",
    "    \n",
    "    starting_scene_params = exp_info['scene_params']\n",
    "    all_predictions = exp_info['es'].predictions\n",
    "    all_prediction_settings = exp_info['es'].prediction_settings\n",
    "    correct_prediction = exp_info['es'].correct_prediction\n",
    "\n",
    "    ids = np.where(np.array(all_predictions) != correct_prediction)\n",
    "    \n",
    "    if len(ids[0]) != 0:\n",
    "        found_adv = True\n",
    "        adv_predictions = np.array(all_predictions)[ids]\n",
    "        adv_prediction_settings = np.array(all_prediction_settings)[ids]\n",
    "\n",
    "        adv_id = random.choice(range(len(ids)))\n",
    "\n",
    "        starting_scene_params = exp_info['scene_params']\n",
    "\n",
    "        adv_scene_params = clone_scene_params(starting_scene_params)\n",
    "        if varying_camera:\n",
    "            adv_scene_params[1]['camera_position'] = torch.tensor(adv_prediction_settings[adv_id][:3]).float()\n",
    "            adv_scene_params[1]['cam_look_at'] = torch.tensor(adv_prediction_settings[adv_id][3:6]).float()\n",
    "            adv_scene_params[1]['cam_up'] = torch.tensor(adv_prediction_settings[adv_id][6:9]).float()\n",
    "            adv_scene_params[1]['fov'] = torch.tensor(adv_prediction_settings[adv_id][9]*10).float()\n",
    "        elif varying_light:\n",
    "            num_lights = int(adv_prediction_settings[adv_id].shape[0]/11)\n",
    "            adv_scene_params[2]['all_light_positions'] = torch.tensor(adv_prediction_settings[adv_id][:num_lights*3]).float().view(num_lights,-1)\n",
    "            adv_scene_params[2]['all_light_look_ats'] = torch.tensor(adv_prediction_settings[adv_id][num_lights*3:num_lights*6]).float().view(num_lights,-1)\n",
    "            adv_scene_params[2]['all_light_intensities'] = torch.tensor(adv_prediction_settings[adv_id][num_lights*6:num_lights*9]).float().view(num_lights,-1)\n",
    "            adv_scene_params[2]['all_light_sizes'] = torch.tensor(adv_prediction_settings[adv_id][num_lights*9:]).float().view(num_lights,-1)\n",
    "        params = [starting_scene_params, adv_scene_params]\n",
    "    else:\n",
    "        found_adv = False\n",
    "        params = [starting_scene_params]\n",
    "    \n",
    "    inps = []\n",
    "    predictions = []\n",
    "    imgs = []\n",
    "    if render:\n",
    "        print('Rendering')\n",
    "        for i in range(len(params)):\n",
    "            param = params[i]\n",
    "            scene, variables = start_up(param, [])\n",
    "\n",
    "            inputs, img = render_input(scene)\n",
    "            imgs.append(img)\n",
    "            \n",
    "            inputs = inputs.cuda()\n",
    "            rendered_inputs = inputs.clone()\n",
    "            inputs = inputs/255.0\n",
    "            im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "            inputs_ = (inputs - im_means)/im_stds\n",
    "            outputs = loaded_model(inputs_)\n",
    "            probability = outputs[0][correct_prediction].item()\n",
    "            prediction = torch.argmax(outputs[0]).item()\n",
    "            predictions.append(prediction)\n",
    "            inps.append(rendered_inputs)    \n",
    "            \n",
    "        if len(inps) == 1:\n",
    "            inps.append(inps[0])\n",
    "            predictions.append(predictions[0])\n",
    "    \n",
    "    if show:\n",
    "        print('Showing')\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "        ax[0].imshow(inps[0][0].cpu().permute(1,2,0).int())\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title('Starting: %s'%(shapenet_class_num_to_class_name[predictions[0]].split(',')[0]))\n",
    "        ax[1].imshow(inps[1][0].cpu().permute(1,2,0).int())\n",
    "        ax[1].axis('off')        \n",
    "        ax[1].set_title('Adversarial: %s'%(shapenet_class_num_to_class_name[predictions[1]].split(',')[0]))\n",
    "        plt.show()\n",
    "        \n",
    "    return found_adv, inps, predictions, imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam_unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "necessary-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam_unseen/resnet18_v7/'\n",
    "# folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam_unseen/resnet18_v7_40/'\n",
    "# folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam_unseen/resnet18_v7_subsampled/'\n",
    "# folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam_unseen/resnet18_v7_truly_shift_invariant/'\n",
    "folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_light/neurips_results/resnet18_antialiased_v7_40_normalized_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prostate-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"%s/saved_images/\"%folder\n",
    "if not os.path.isdir(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprising-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_save_folder = \"%s/saved_renders/\"%folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incorporated-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(rendered_save_folder):\n",
    "    os.mkdir(rendered_save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "living-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_light/neurips_results/resnet18_antialiased_v7_40_normalized_final//saved_renders/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "handed-feeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_light/neurips_results/resnet18_antialiased_v7_40_normalized_final//saved_renders/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "spread-dallas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "explicit-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_list = [\"JPcevyd9BJiO9m8r\", \"nDS9g1aQFy0cuAnu\", \"qwJOCIXZJ2HWjq84\", \"zf8s08TeeTdJLbuF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "handled-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = \"zf8s08TeeTdJLbuF.p\"\n",
    "# exp_path = \"%s/%s\"%(folder, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "academic-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(exp_path, 'rb') as F:\n",
    "#     exp_info = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "utility-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_scene_params = exp_info['scene_params']\n",
    "all_predictions = exp_info['es'].predictions\n",
    "all_prediction_settings = exp_info['es'].prediction_settings\n",
    "correct_prediction = exp_info['es'].correct_prediction\n",
    "\n",
    "ids = np.where(np.array(all_predictions) != correct_prediction)\n",
    "\n",
    "if len(ids[0]) != 0:\n",
    "    found_adv = True\n",
    "    adv_predictions = np.array(all_predictions)[ids]\n",
    "    adv_prediction_settings = np.array(all_prediction_settings)[ids]\n",
    "\n",
    "    adv_id = random.choice(range(len(ids)))\n",
    "\n",
    "    starting_scene_params = exp_info['scene_params']\n",
    "\n",
    "    adv_scene_params = clone_scene_params(starting_scene_params)\n",
    "    if varying_camera:\n",
    "        adv_scene_params[1]['camera_position'] = torch.tensor(adv_prediction_settings[adv_id][:3]).float()\n",
    "        adv_scene_params[1]['cam_look_at'] = torch.tensor(adv_prediction_settings[adv_id][3:6]).float()\n",
    "        adv_scene_params[1]['cam_up'] = torch.tensor(adv_prediction_settings[adv_id][6:9]).float()\n",
    "        adv_scene_params[1]['fov'] = torch.tensor(adv_prediction_settings[adv_id][9]*10).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dying-round",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['camera_position', 'cam_look_at', 'fov', 'cam_up'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_scene_params[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "distinct-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.32, -0.65, -0.68\n",
      "0.26, 0.37, 0.04\n",
      "80.09\n",
      "-0.34, -0.83, -0.52\n"
     ]
    }
   ],
   "source": [
    "for key in starting_scene_params[1].keys():\n",
    "    try:\n",
    "        A = list(np.array(starting_scene_params[1][key]))\n",
    "        print('%.02f, %.02f, %.02f'%(A[0], A[1], A[2]))\n",
    "    except:\n",
    "        print(\"%.02f\"%np.array(starting_scene_params[1][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "recreational-breathing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.25, -0.72, -0.69\n",
      "0.30, 0.33, 0.06\n",
      "80.18\n",
      "-3.36, -8.30, -5.20\n"
     ]
    }
   ],
   "source": [
    "for key in adv_scene_params[1].keys():\n",
    "    try:\n",
    "        A = list(np.array(adv_scene_params[1][key]))\n",
    "        print('%.02f, %.02f, %.02f'%(A[0], A[1], A[2]))\n",
    "    except:\n",
    "        print(\"%.02f\"%np.array(adv_scene_params[1][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "immediate-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.isfile(exp_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "toxic-device",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# success_count = 0\n",
    "# total = 0\n",
    "# for exp in tqdm(os.listdir(folder)):\n",
    "#     if '.p' in exp:\n",
    "#         exp_p = \"%s/%s\"%(folder, exp)        \n",
    "#         found_adv, rendered_inputs, predictions, images = evaluate_exp(exp_p, render = True, show = False)\n",
    "        \n",
    "# #         starting_image_path = \"%s/%s_starting_%s.png\"%(save_folder, exp_p.split('/')[-1].split('.p')[0], predictions[0])\n",
    "# #         show_inputs(rendered_inputs[0], save_path = starting_image_path)\n",
    "        \n",
    "#         starting_render_path = \"%s/%s_starting_%s.png\"%(rendered_save_folder, exp_p.split('/')[-1].split('.p')[0], predictions[0])\n",
    "#         start_image = Image.fromarray(images[0].cpu().numpy().astype('uint8'))\n",
    "#         start_image.save(starting_render_path)\n",
    "\n",
    "#         if found_adv == True:\n",
    "# #             adv_image_path = \"%s/%s_adversarial_%s.png\"%(save_folder, exp_p.split('/')[-1].split('.p')[0], predictions[1])\n",
    "# #             show_inputs(rendered_inputs[1], save_path = adv_image_path)\n",
    "\n",
    "#             adv_render_path = \"%s/%s_adversarial_%s.png\"%(rendered_save_folder, exp_p.split('/')[-1].split('.p')[0], predictions[1])\n",
    "#             adv_image = Image.fromarray(images[1].cpu().numpy().astype('uint8'))\n",
    "#             adv_image.save(adv_render_path)\n",
    "#             success_count += 1\n",
    "#         if total == 105:\n",
    "#             break\n",
    "#         total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "empirical-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "varying-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "incredible-minutes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28828828828828834"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-success_count/(total+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-progress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
