{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/__init__.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader/multi_attribute_loader.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader/loader.py\n",
      "/net/storage001.ib.cluster/om2/user/smadan/training_scaffold_own/res/loader\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML, Javascript\n",
    "\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../inverse_rendering/')\n",
    "from general_imports import *\n",
    "from tqdm import tqdm as tqdm_file\n",
    "import argparse\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "from numpy import asarray\n",
    "from numpy import exp\n",
    "from numpy import sqrt\n",
    "from numpy import cos\n",
    "from numpy import e\n",
    "from numpy import pi\n",
    "from numpy import argsort\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dimensional-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/storage001.ib.cluster/om2/user/smadan/differentiable_graphics_ml/other_optimization_methods\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "portuguese-legend",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.listdir('../training_models/saved_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sound-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphanumeric_key = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "# print(\"Key is: %s\"%alphanumeric_key)\n",
    "\n",
    "##### Load Model #####\n",
    "#model_path = '../training_models/saved_models/resnet18_antialiased_v7_normalized_final.pt'\n",
    "# model_path = '../training_models/saved_models/resnet18_v7_subsampled_normalized_final.pt'\n",
    "#model_path = '../training_models/saved_models/resnet18_v7_places_normalized.pt'\n",
    "# model_path = '../training_models/saved_models/resnet18_v7_40_final.pt'\n",
    "model_path = '../training_models/saved_models/resnet18_v7_truly_shift_invariant_normalized_final.pt'\n",
    "loaded_model = torch.load(model_path)\n",
    "softmax_layer = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "respected-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = 'cma_adversarial_cam/resnet18/saved_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statutory-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = [\"%s/%s\"%(images_folder, i) for i in os.listdir(images_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "incident-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cma_adversarial_cam/resnet18/saved_images//hyUHmJHlkfGEdLB4_starting_7.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fifth-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(all_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-ethiopia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Shapenet Category etc. ####\n",
    "with open('../training_models/shapenet_class_num_to_class_name.p','rb') as F:\n",
    "    shapenet_class_num_to_class_name = pickle.load(F)\n",
    "with open('../training_models/shapenet_id_to_class_num.p','rb') as F:\n",
    "    shapenet_id_to_class_num = pickle.load(F)\n",
    "\n",
    "##### Randomization Functions ######\n",
    "\n",
    "RADIUS_MIN = 8.0\n",
    "RADIUS_MAX = 14.0\n",
    "MIN_NUM_LIGHTS = 1\n",
    "MAX_NUM_LIGHTS = 4\n",
    "\n",
    "RADIUS_MIN_CAM = 2.0\n",
    "RADIUS_MAX_CAM = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniform_on_sphere(num_points, radius):\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        X = np.random.normal()\n",
    "        Y = np.random.normal()\n",
    "        Z = np.random.normal()\n",
    "\n",
    "        vector = np.array([X,Y,Z])\n",
    "        point = list(radius*vector/np.linalg.norm(vector))\n",
    "        points.append(point)\n",
    "    return points\n",
    "def get_cam_position(radius_min, radius_max):\n",
    "    random_radius = random.uniform(radius_min, radius_max)\n",
    "    cam_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "    cam_point = torch.tensor(cam_point).float()\n",
    "\n",
    "    return cam_point\n",
    "def get_positions(min_num_lights, max_num_lights, radius_min, radius_max):\n",
    "    num_lights = random.choice(range(min_num_lights, max_num_lights + 1))\n",
    "    light_positions = []\n",
    "\n",
    "    for num in range(num_lights):\n",
    "        random_radius = random.uniform(radius_min, radius_max)\n",
    "        light_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "        light_point = torch.tensor(light_point).float()\n",
    "        light_positions.append(light_point)\n",
    "\n",
    "    return light_positions\n",
    "def get_random_intensity():\n",
    "    light_intensity = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)]).float()\n",
    "    return light_intensity\n",
    "def get_random_reflectance():\n",
    "    specular_reflectance = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)], device = pyredner.get_device()).float()\n",
    "    return specular_reflectance\n",
    "def get_random_look_at(radius):\n",
    "    K = 0.3\n",
    "    look_at = torch.tensor([random.uniform(0,K*radius), random.uniform(0,K*radius), random.uniform(0,K*radius)]).float()\n",
    "    return look_at\n",
    "def get_random_scene_params(model_file):\n",
    "    ### Random Camera Settings ###\n",
    "    camera_position = get_cam_position(RADIUS_MIN_CAM, RADIUS_MAX_CAM)\n",
    "    cam_radius = torch.sqrt(camera_position[0]**2 + camera_position[1]**2 + camera_position[2]**2).item()\n",
    "    cam_look_at = get_random_look_at(cam_radius)\n",
    "    fov = torch.tensor(random.uniform(35,100))\n",
    "    cam_up = torch.tensor([random.uniform(-1,1), random.uniform(-1,1), random.uniform(-1,1)])\n",
    "    initial_camera_params = {'camera_position': camera_position,\n",
    "                             'cam_look_at': cam_look_at,\n",
    "                             'fov': fov,\n",
    "                             'cam_up': cam_up}\n",
    "\n",
    "\n",
    "    ### Random Light Settings ###\n",
    "    all_light_positions = get_positions(MIN_NUM_LIGHTS, MAX_NUM_LIGHTS, RADIUS_MIN, RADIUS_MAX)\n",
    "    all_light_look_ats = [get_random_look_at(cam_radius) for i in all_light_positions]\n",
    "    all_light_intensities = [get_random_intensity() for i in all_light_positions]\n",
    "    all_light_sizes = [torch.tensor([random.uniform(0.1,5.0), random.uniform(0.1, 5.0)]) for i in all_light_positions]\n",
    "    initial_light_params = {'all_light_positions': all_light_positions,\n",
    "                            'all_light_look_ats': all_light_look_ats,\n",
    "                            'all_light_intensities': all_light_intensities,\n",
    "                            'all_light_sizes': all_light_sizes}\n",
    "\n",
    "    #### Material ####\n",
    "    diffuse_material = pyredner.Material(diffuse_reflectance = torch.tensor([1.0, 1.0, 1.0], \\\n",
    "                                        device='cuda:0'), two_sided = True)\n",
    "    material_settings = {'diffuse_material':diffuse_material}\n",
    "\n",
    "    scene_params = [model_file, initial_camera_params, initial_light_params, material_settings]\n",
    "    return scene_params\n",
    "def show_inputs(inp, save_path = False, title='No Title'):\n",
    "    plt.imshow(inp[0].cpu().permute(1,2,0).int())\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    if save_path != False:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()\n",
    "def render_input(scene):\n",
    "    img = pyredner.render_pathtracing(scene = scene, num_samples = 256, seed = 1, use_secondary_edge_sampling = False)\n",
    "    img = torch.clamp(img, min = 0.00000001)\n",
    "    img = torch.pow(img, 1.0/2.2)\n",
    "    img = img*255/torch.max(img)\n",
    "    inputs = img.permute(2,0,1).unsqueeze(0)\n",
    "    return inputs\n",
    "def spherical_to_cartesian(r,theta,phi):\n",
    "    theta_rad = theta*3.14/180\n",
    "    phi_rad = phi*3.14/180\n",
    "\n",
    "    x = r * torch.sin(phi_rad) * torch.cos(theta_rad)\n",
    "    y = r * torch.sin(phi_rad) * torch.sin(theta_rad)\n",
    "    z = r * torch.cos(phi_rad)\n",
    "    out =  torch.stack([x,y,z])\n",
    "    return out\n",
    "def load_geometry(model_file, geometry, mat):\n",
    "    if geometry:\n",
    "        obj_model_all = model_file\n",
    "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "    else:\n",
    "        obj_model_all = pyredner.load_obj(model_file, return_objects=True)\n",
    "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "\n",
    "    for part in obj_model:\n",
    "        part.material = mat\n",
    "\n",
    "    return obj_model\n",
    "def optimize_flags(obj):\n",
    "    if type(obj) == list:\n",
    "        for o in obj:\n",
    "            o.requires_grad = True\n",
    "    else:\n",
    "        obj.requires_grad = True\n",
    "    return obj\n",
    "def setup_scene(scene_params):\n",
    "\n",
    "    model_file, camera_params, light_params, material_settings = scene_params\n",
    "    obj_model = load_geometry(model_file, False, material_settings['diffuse_material'])\n",
    "\n",
    "    #### Camera Setup ####\n",
    "    scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224),\n",
    "                                                   fov = torch.tensor([camera_params['fov']]),\n",
    "                                                   up = camera_params['cam_up'],\n",
    "                                                   look_at = camera_params['cam_look_at'])\n",
    "    scene_cam.position = camera_params['camera_position']\n",
    "\n",
    "    #### Lights Setup ####\n",
    "    scene_lights = []\n",
    "    num_lights = len(light_params['all_light_positions'])\n",
    "    for i in range(num_lights):\n",
    "        scene_light = pyredner.generate_quad_light(position = light_params['all_light_positions'][i],\n",
    "                                     look_at = light_params['all_light_look_ats'][i],\n",
    "                                     size = light_params['all_light_sizes'][i],\n",
    "                                     intensity = light_params['all_light_intensities'][i],\n",
    "                                     directly_visible = False)\n",
    "        scene_lights.append(scene_light)\n",
    "\n",
    "    all_objects = obj_model + scene_lights\n",
    "    scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
    "\n",
    "    return scene\n",
    "def start_up(scene_params, optimized_params):\n",
    "    model_file, camera_params, light_params, material_settings = scene_params\n",
    "    variables = []\n",
    "    var_names_list = []\n",
    "    for param in optimized_params:\n",
    "        if param in camera_params.keys():\n",
    "            optimize_flags(camera_params[param])\n",
    "            if type(camera_params[param]) == list:\n",
    "                variables.extend(camera_params[param])\n",
    "            else:\n",
    "                variables.append(camera_params[param])\n",
    "        elif param in light_params.keys():\n",
    "            optimize_flags(light_params[param])\n",
    "            if type(light_params[param]) == list:\n",
    "                variables.extend(light_params[param])\n",
    "            else:\n",
    "                variables.append(light_params[param])\n",
    "\n",
    "    scene_params = [model_file, camera_params, light_params, material_settings]\n",
    "    scene = setup_scene(scene_params)\n",
    "\n",
    "    return scene, variables\n",
    "def get_random_3d_model():\n",
    "    model_files_pickle = '../rendering/shapenet_model_subsets/categories_10_models_10.pkl'\n",
    "    with open(model_files_pickle, 'rb') as F:\n",
    "        model_files = pickle.load(F)\n",
    "    random_category = random.choice(list(model_files.keys()))\n",
    "    random_instance = random.choice(model_files[random_category]).split('/')[7]\n",
    "    model_file = '%s/ShapeNetCore.v2/%s/%s/models/model_normalized.obj'%(user_root_dir, random_category, random_instance)\n",
    "    print('Chosen model is a %s'%shapenet_class_num_to_class_name[shapenet_id_to_class_num[random_category]])\n",
    "    category_num = shapenet_id_to_class_num[random_category]\n",
    "    print('Category num is %s'%category_num)\n",
    "    return model_file, category_num, random_category, random_instance\n",
    "def perturbation_vector(factor_len, perturb_percent = 1):\n",
    "    if factor_len == 0:\n",
    "        factor_len = 1\n",
    "    vec = torch.tensor([random.uniform(-perturb_percent/100,perturb_percent/100) for i in range(factor_len)])\n",
    "    return 1 + vec\n",
    "def random_perturbed_params(scene_params, perturb_percent = 1):\n",
    "    new_scene_params = [0,0,0,0]\n",
    "    new_scene_params[0] = scene_params[0]\n",
    "\n",
    "    new_scene_params[1] = {}\n",
    "    for key in scene_params[1].keys():\n",
    "        new_scene_params[1][key] = scene_params[1][key].clone() * perturbation_vector(scene_params[1][key].dim(), perturb_percent)\n",
    "\n",
    "    new_scene_params[2] = {}\n",
    "    for key in scene_params[2].keys():\n",
    "        new_scene_params[2][key] = [i.clone() * perturbation_vector(i.dim(), perturb_percent) for i in scene_params[2][key]]\n",
    "\n",
    "    new_scene_params[3] = scene_params[3]\n",
    "    return new_scene_params\n",
    "def render_and_predict(scene_params, optimized_params):\n",
    "    scene, variables = start_up(scene_params, optimized_params)\n",
    "    inputs = render_input(scene)\n",
    "    inputs = inputs.cuda()\n",
    "    rendered_inputs = inputs.clone()\n",
    "    inputs = inputs/255.0\n",
    "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    inputs_ = (inputs - im_means)/im_stds\n",
    "    outputs = softmax_layer(loaded_model(inputs_))\n",
    "    prediction = torch.argmax(outputs).item()\n",
    "    return prediction, rendered_inputs\n",
    "def create_folder(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "def clone_scene_params(scene_params):\n",
    "    original_scene_params = [0,0,0,0]\n",
    "    original_scene_params[0] = scene_params[0]\n",
    "\n",
    "    original_scene_params[1] = {}\n",
    "    for key in scene_params[1].keys():\n",
    "        original_scene_params[1][key] = scene_params[1][key].clone()\n",
    "\n",
    "    original_scene_params[2] = {}\n",
    "    for key in scene_params[2].keys():\n",
    "        original_scene_params[2][key] = [i.clone() for i in scene_params[2][key]]\n",
    "\n",
    "    original_scene_params[3] = scene_params[3]\n",
    "    return original_scene_params\n",
    "\n",
    "def plot_losses(losses):\n",
    "    plt.plot(losses, marker='o',color='green')\n",
    "    plt.title('Losses',fontsize=16)\n",
    "    plt.xticks(fontsize= 12)\n",
    "    plt.yticks(fontsize= 12)\n",
    "    plt.show()\n",
    "\n",
    "def check_in_range(scene_params):\n",
    "    if scene_params[0] == 0:\n",
    "        return False\n",
    "    cam_radius = torch.norm(scene_params[1]['camera_position'])\n",
    "    radius_check = RADIUS_MIN_CAM <= cam_radius <= RADIUS_MAX_CAM\n",
    "    look_at_check = torch.sum(scene_params[1]['cam_look_at'] < cam_radius*0.3).item() == 3\n",
    "    return radius_check and look_at_check\n",
    "\n",
    "def objective(scene_params, optimized_params, neuron_num = None):\n",
    "    scene, variables = start_up(scene_params, [])\n",
    "    inputs = render_input(scene)\n",
    "    inputs = inputs.cuda()\n",
    "    rendered_inputs = inputs.clone()\n",
    "    inputs = inputs/255.0\n",
    "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    inputs_ = (inputs - im_means)/im_stds\n",
    "    outputs = shorter_model(inputs_)\n",
    "    if neuron_num is None:\n",
    "        selective_neurons = torch.argsort(outputs[0].view(512,-1).squeeze(1))[-1]\n",
    "        selected_act_firing = outputs[0].view(512,-1).squeeze(1)[selective_neurons]\n",
    "        return selective_neurons, selected_act_firing\n",
    "    else:\n",
    "        loss = torch.sum(outputs[0].view(512,-1).squeeze(1)[neuron_num]).item()\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def cma_objective_adversarial(x):\n",
    "    SCENE_PARAMS[1]['camera_position'] = torch.tensor(x[:3]).float()\n",
    "    SCENE_PARAMS[1]['cam_look_at'] = torch.tensor(x[3:6]).float()\n",
    "    SCENE_PARAMS[1]['cam_up'] = torch.tensor(x[6:9]/10).float()\n",
    "    SCENE_PARAMS[1]['fov'] = torch.tensor(x[9]*10).float()\n",
    "\n",
    "    scene, variables = start_up(SCENE_PARAMS, [])\n",
    "    inputs = render_input(scene)\n",
    "    inputs = inputs.cuda()\n",
    "    rendered_inputs = inputs.clone()\n",
    "    inputs = inputs/255.0\n",
    "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    inputs_ = (inputs - im_means)/im_stds\n",
    "    outputs = loaded_model(inputs_)\n",
    "    probability = outputs[0][CATEGORY_NUM].item()\n",
    "    prediction = torch.argmax(outputs[0]).item()\n",
    "    return probability, prediction\n",
    "\n",
    "\n",
    "model_file, category_num, category, instance = get_random_3d_model()\n",
    "optimized_params = []\n",
    "curr_pred = -1\n",
    "while curr_pred != category_num:\n",
    "    scene_params = get_random_scene_params(model_file)\n",
    "    original_scene_params = clone_scene_params(scene_params)\n",
    "    curr_pred, _ = render_and_predict(scene_params, [])\n",
    "\n",
    "import cma\n",
    "\n",
    "cp = np.array(scene_params[1]['camera_position'])\n",
    "cat = np.array(scene_params[1]['cam_look_at'])\n",
    "cup = np.array(scene_params[1]['cam_up'])*10\n",
    "fov = np.array(scene_params[1]['fov'])/10\n",
    "start_pos = np.hstack([cp,cat,cup,fov])\n",
    "\n",
    "SCENE_PARAMS = clone_scene_params(scene_params)\n",
    "CATEGORY_NUM = category_num\n",
    "\n",
    "es = cma.CMAEvolutionStrategy(start_pos, 0.05)\n",
    "\n",
    "es.optimize(cma_objective_adversarial, verb_disp = True, iterations=25, correct_prediction = category_num)\n",
    "print(es.predictions)\n",
    "\n",
    "folder = '/om5/user/smadan/differentiable_graphics_ml/other_optimization_methods/cma_adversarial_cam/resnet18_v7_40/'\n",
    "info_to_store = {}\n",
    "\n",
    "info_to_store['scene_params'] = scene_params\n",
    "info_to_store['es'] = es\n",
    "with open('%s/%s.p'%(folder, alphanumeric_key), 'wb') as F:\n",
    "    pickle.dump(info_to_store, F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
