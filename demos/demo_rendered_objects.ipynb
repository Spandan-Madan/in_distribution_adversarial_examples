{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP60oenY37fzHUuqbHZ04la",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spandan-Madan/in_distribution_adversarial_examples/blob/main/demos/demo_rendered_objects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Spandan-Madan/in_distribution_adversarial_examples\n",
        "!pip install redner-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMh33nDLN_Lm",
        "outputId": "1a6e1c16-9e25-4cb6-b0e7-ca8fb7afb1ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'in_distribution_adversarial_examples'...\n",
            "remote: Enumerating objects: 626, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 626 (delta 16), reused 29 (delta 4), pack-reused 569\u001b[K\n",
            "Receiving objects: 100% (626/626), 91.37 MiB | 13.79 MiB/s, done.\n",
            "Resolving deltas: 100% (151/151), done.\n",
            "Updating files: 100% (561/561), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting redner-gpu\n",
            "  Downloading redner_gpu-0.4.28-cp38-cp38-manylinux1_x86_64.whl (31.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.9/31.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from redner-gpu) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from redner-gpu) (2.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio->redner-gpu) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio->redner-gpu) (1.22.4)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->redner-gpu) (3.5.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->redner-gpu) (1.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->redner-gpu) (1.7.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->redner-gpu) (2023.2.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->redner-gpu) (3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image->redner-gpu) (1.15.0)\n",
            "Installing collected packages: redner-gpu\n",
            "Successfully installed redner-gpu-0.4.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q_WmLzfbMU5L"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML, Javascript\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# sys.path.append('../inverse_rendering/')\n",
        "import torch\n",
        "from torch.distributions import Normal\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "from tqdm import tqdm as tqdm_file\n",
        "import argparse\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "NTYwEoL4MYoh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import asarray\n",
        "from numpy import exp\n",
        "from numpy import sqrt\n",
        "from numpy import cos\n",
        "from numpy import e\n",
        "from numpy import pi\n",
        "from numpy import argsort\n",
        "from numpy.random import randn\n",
        "from numpy.random import rand\n",
        "from numpy.random import seed\n",
        "import pickle"
      ],
      "metadata": {
        "id": "6tdb3__2Mhi6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "pF7-RZNDOWYm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import redner"
      ],
      "metadata": {
        "id": "tKKL9Ib_b5C0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pyredner"
      ],
      "metadata": {
        "id": "sMjoXBqMb6eB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '/content/in_distribution_adversarial_examples/'\n",
        "REDNER_ROOT = '/content/in_distribution_adversarial_examples/redner/'\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0,ROOT)\n",
        "sys.path.insert(0,REDNER_ROOT)\n",
        "import redner\n",
        "import pyredner\n"
      ],
      "metadata": {
        "id": "Ugz-HG0GMjGd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cma"
      ],
      "metadata": {
        "id": "cOY_KzMsXXof"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(ROOT, 'training_models/saved_models/resnet18_pretrained_v7_40_normalized_final.pt')\n",
        "loaded_model = torch.load(model_path)\n",
        "softmax_layer = nn.Softmax()"
      ],
      "metadata": {
        "id": "o3dmMqi7NLFH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('%s/training_models/shapenet_class_num_to_class_name.p'%ROOT,'rb') as F:\n",
        "    shapenet_class_num_to_class_name = pickle.load(F)\n",
        "with open('%s/training_models/shapenet_id_to_class_num.p'%ROOT,'rb') as F:\n",
        "    shapenet_id_to_class_num = pickle.load(F)"
      ],
      "metadata": {
        "id": "5uYyoMIKNSoY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RADIUS_MIN = 3.0\n",
        "RADIUS_MAX = 4.0\n",
        "MIN_NUM_LIGHTS = 1\n",
        "MAX_NUM_LIGHTS = 4\n",
        "\n",
        "RADIUS_MIN_CAM = 1.0\n",
        "RADIUS_MAX_CAM = 5.0"
      ],
      "metadata": {
        "id": "hHZJTF15PYcu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_uniform_on_sphere(num_points, radius):\n",
        "    points = []\n",
        "    for i in range(num_points):\n",
        "        X = np.random.normal()\n",
        "        Y = np.random.normal()\n",
        "        Z = np.random.normal()\n",
        "\n",
        "        vector = np.array([X,Y,Z])\n",
        "        point = list(radius*vector/np.linalg.norm(vector))\n",
        "        points.append(point)\n",
        "    return points"
      ],
      "metadata": {
        "id": "5bLYNAYBQYfN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cam_position(radius_min, radius_max):\n",
        "    random_radius = random.uniform(radius_min, radius_max)\n",
        "    cam_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
        "    cam_point = torch.tensor(cam_point).float()\n",
        "\n",
        "    return cam_point\n",
        "def get_positions(min_num_lights, max_num_lights, radius_min, radius_max):\n",
        "    num_lights = random.choice(range(min_num_lights, max_num_lights + 1))\n",
        "    light_positions = []\n",
        "\n",
        "    for num in range(num_lights):\n",
        "        random_radius = random.uniform(radius_min, radius_max)\n",
        "        light_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
        "        light_point = torch.tensor(light_point).float()\n",
        "        light_positions.append(light_point)\n",
        "\n",
        "    return light_positions\n",
        "def get_random_intensity():\n",
        "    light_intensity = torch.tensor([random.uniform(0,1), \\\n",
        "                                    random.uniform(0,1), random.uniform(0,1)]).float()\n",
        "    return light_intensity\n",
        "def get_random_reflectance():\n",
        "    specular_reflectance = torch.tensor([random.uniform(0,1), \\\n",
        "                                    random.uniform(0,1), random.uniform(0,1)], device = pyredner.get_device()).float()\n",
        "    return specular_reflectance\n",
        "def get_random_look_at(radius):\n",
        "    K = 0.3\n",
        "    look_at = torch.tensor([random.uniform(0,K*radius), random.uniform(0,K*radius), random.uniform(0,K*radius)]).float()\n",
        "    return look_at\n",
        "def get_random_scene_params(model_file):\n",
        "    ### Random Camera Settings ###\n",
        "    camera_position = get_cam_position(RADIUS_MIN_CAM, RADIUS_MAX_CAM)\n",
        "    cam_radius = torch.sqrt(camera_position[0]**2 + camera_position[1]**2 + camera_position[2]**2).item()\n",
        "    cam_look_at = get_random_look_at(cam_radius)\n",
        "    fov = torch.tensor(random.uniform(35,100))\n",
        "    cam_up = torch.tensor([random.uniform(-1,1), random.uniform(-1,1), random.uniform(-1,1)])\n",
        "    initial_camera_params = {'camera_position': camera_position,\n",
        "                             'cam_look_at': cam_look_at,\n",
        "                             'fov': fov,\n",
        "                             'cam_up': cam_up}\n",
        "\n",
        "\n",
        "    ### Random Light Settings ###\n",
        "    all_light_positions = get_positions(MIN_NUM_LIGHTS, MAX_NUM_LIGHTS, RADIUS_MIN, RADIUS_MAX)\n",
        "    all_light_look_ats = [get_random_look_at(cam_radius) for i in all_light_positions]\n",
        "    all_light_intensities = [get_random_intensity() for i in all_light_positions]\n",
        "    all_light_sizes = [torch.tensor([random.uniform(0.1,5.0), random.uniform(0.1, 5.0)]) for i in all_light_positions]\n",
        "    initial_light_params = {'all_light_positions': all_light_positions,\n",
        "                            'all_light_look_ats': all_light_look_ats,\n",
        "                            'all_light_intensities': all_light_intensities,\n",
        "                            'all_light_sizes': all_light_sizes}\n",
        "\n",
        "    #### Material ####\n",
        "    diffuse_material = pyredner.Material(diffuse_reflectance = torch.tensor([1.0, 1.0, 1.0], \\\n",
        "                                        device='cuda:0'), two_sided = True)\n",
        "    material_settings = {'diffuse_material':diffuse_material}\n",
        "\n",
        "    scene_params = [model_file, initial_camera_params, initial_light_params, material_settings]\n",
        "    return scene_params\n",
        "def show_inputs(inp, save_path = False, title='No Title'):\n",
        "    plt.imshow(inp[0].cpu().permute(1,2,0).int())\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    if save_path != False:\n",
        "        plt.savefig(save_path)\n",
        "    else:\n",
        "        plt.show()\n",
        "def render_input(scene):\n",
        "    img = pyredner.render_pathtracing(scene = scene, num_samples = 256, seed = 1, use_secondary_edge_sampling = False)\n",
        "    img = torch.clamp(img, min = 0.00000001)\n",
        "    img = torch.pow(img, 1.0/2.2)\n",
        "    img = img*255/torch.max(img)\n",
        "    inputs = img.permute(2,0,1).unsqueeze(0)\n",
        "    return inputs\n",
        "def spherical_to_cartesian(r,theta,phi):\n",
        "    theta_rad = theta*3.14/180\n",
        "    phi_rad = phi*3.14/180\n",
        "\n",
        "    x = r * torch.sin(phi_rad) * torch.cos(theta_rad)\n",
        "    y = r * torch.sin(phi_rad) * torch.sin(theta_rad)\n",
        "    z = r * torch.cos(phi_rad)\n",
        "    out =  torch.stack([x,y,z])\n",
        "    return out\n",
        "def load_geometry(model_file, geometry, mat):\n",
        "    if geometry:\n",
        "        obj_model_all = model_file\n",
        "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
        "    else:\n",
        "        obj_model_all = pyredner.load_obj(model_file, return_objects=True)\n",
        "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
        "\n",
        "    for part in obj_model:\n",
        "        part.material = mat\n",
        "\n",
        "    return obj_model\n",
        "def optimize_flags(obj):\n",
        "    if type(obj) == list:\n",
        "        for o in obj:\n",
        "            o.requires_grad = True\n",
        "    else:\n",
        "        obj.requires_grad = True\n",
        "    return obj\n",
        "def setup_scene(scene_params):\n",
        "\n",
        "    model_file, camera_params, light_params, material_settings = scene_params\n",
        "    obj_model = load_geometry(model_file, False, material_settings['diffuse_material'])\n",
        "\n",
        "    #### Camera Setup ####\n",
        "    scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224),\n",
        "                                                   fov = torch.tensor([camera_params['fov']]),\n",
        "                                                   up = camera_params['cam_up'],\n",
        "                                                   look_at = camera_params['cam_look_at'])\n",
        "    scene_cam.position = camera_params['camera_position']\n",
        "\n",
        "    #### Lights Setup ####\n",
        "    scene_lights = []\n",
        "    num_lights = len(light_params['all_light_positions'])\n",
        "    for i in range(num_lights):\n",
        "        scene_light = pyredner.generate_quad_light(position = light_params['all_light_positions'][i],\n",
        "                                     look_at = light_params['all_light_look_ats'][i],\n",
        "                                     size = light_params['all_light_sizes'][i],\n",
        "                                     intensity = light_params['all_light_intensities'][i],\n",
        "                                     directly_visible = False)\n",
        "        scene_lights.append(scene_light)\n",
        "\n",
        "    all_objects = obj_model + scene_lights\n",
        "    scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
        "\n",
        "    return scene\n",
        "def start_up(scene_params, optimized_params):\n",
        "    model_file, camera_params, light_params, material_settings = scene_params\n",
        "    variables = []\n",
        "    var_names_list = []\n",
        "    for param in optimized_params:\n",
        "        if param in camera_params.keys():\n",
        "            optimize_flags(camera_params[param])\n",
        "            if type(camera_params[param]) == list:\n",
        "                variables.extend(camera_params[param])\n",
        "            else:\n",
        "                variables.append(camera_params[param])\n",
        "        elif param in light_params.keys():\n",
        "            optimize_flags(light_params[param])\n",
        "            if type(light_params[param]) == list:\n",
        "                variables.extend(light_params[param])\n",
        "            else:\n",
        "                variables.append(light_params[param])\n",
        "\n",
        "    scene_params = [model_file, camera_params, light_params, material_settings]\n",
        "    scene = setup_scene(scene_params)\n",
        "\n",
        "    return scene, variables\n",
        "\n",
        "def perturbation_vector(factor_len, perturb_percent = 1):\n",
        "    if factor_len == 0:\n",
        "        factor_len = 1\n",
        "    vec = torch.tensor([random.uniform(-perturb_percent/100,perturb_percent/100) for i in range(factor_len)])\n",
        "    return 1 + vec\n",
        "def random_perturbed_params(scene_params, perturb_percent = 1):\n",
        "    new_scene_params = [0,0,0,0]\n",
        "    new_scene_params[0] = scene_params[0]\n",
        "\n",
        "    new_scene_params[1] = {}\n",
        "    for key in scene_params[1].keys():\n",
        "        new_scene_params[1][key] = scene_params[1][key].clone() * perturbation_vector(scene_params[1][key].dim(), perturb_percent)\n",
        "\n",
        "    new_scene_params[2] = {}\n",
        "    for key in scene_params[2].keys():\n",
        "        new_scene_params[2][key] = [i.clone() * perturbation_vector(i.dim(), perturb_percent) for i in scene_params[2][key]]\n",
        "\n",
        "    new_scene_params[3] = scene_params[3]\n",
        "    return new_scene_params\n",
        "def render_and_predict(scene_params, optimized_params):\n",
        "    scene, variables = start_up(scene_params, optimized_params)\n",
        "    inputs = render_input(scene)\n",
        "    inputs = inputs.cuda()\n",
        "    rendered_inputs = inputs.clone()\n",
        "    inputs = inputs/255.0\n",
        "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    inputs_ = (inputs - im_means)/im_stds\n",
        "    outputs = softmax_layer(loaded_model(inputs_))\n",
        "    prediction = torch.argmax(outputs).item()\n",
        "    return prediction, rendered_inputs\n",
        "def create_folder(folder):\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)\n",
        "def clone_scene_params(scene_params):\n",
        "    original_scene_params = [0,0,0,0]\n",
        "    original_scene_params[0] = scene_params[0]\n",
        "\n",
        "    original_scene_params[1] = {}\n",
        "    for key in scene_params[1].keys():\n",
        "        original_scene_params[1][key] = scene_params[1][key].clone()\n",
        "\n",
        "    original_scene_params[2] = {}\n",
        "    for key in scene_params[2].keys():\n",
        "        original_scene_params[2][key] = [i.clone() for i in scene_params[2][key]]\n",
        "\n",
        "    original_scene_params[3] = scene_params[3]\n",
        "    return original_scene_params\n",
        "\n",
        "def plot_losses(losses):\n",
        "    plt.plot(losses, marker='o',color='green')\n",
        "    plt.title('Losses',fontsize=16)\n",
        "    plt.xticks(fontsize= 12)\n",
        "    plt.yticks(fontsize= 12)\n",
        "    plt.show()\n",
        "\n",
        "def check_in_range(scene_params):\n",
        "    if scene_params[0] == 0:\n",
        "        return False\n",
        "    cam_radius = torch.norm(scene_params[1]['camera_position'])\n",
        "    radius_check = RADIUS_MIN_CAM <= cam_radius <= RADIUS_MAX_CAM\n",
        "    look_at_check = torch.sum(scene_params[1]['cam_look_at'] < cam_radius*0.3).item() == 3\n",
        "    return radius_check and look_at_check\n",
        "\n",
        "def objective(scene_params, optimized_params, neuron_num = None):\n",
        "    scene, variables = start_up(scene_params, [])\n",
        "    inputs = render_input(scene)\n",
        "    inputs = inputs.cuda()\n",
        "    rendered_inputs = inputs.clone()\n",
        "    inputs = inputs/255.0\n",
        "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    inputs_ = (inputs - im_means)/im_stds\n",
        "    outputs = shorter_model(inputs_)\n",
        "    if neuron_num is None:\n",
        "        selective_neurons = torch.argsort(outputs[0].view(512,-1).squeeze(1))[-1]\n",
        "        selected_act_firing = outputs[0].view(512,-1).squeeze(1)[selective_neurons]\n",
        "        return selective_neurons, selected_act_firing\n",
        "    else:\n",
        "        loss = torch.sum(outputs[0].view(512,-1).squeeze(1)[neuron_num]).item()\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "def cma_objective_adversarial(x):\n",
        "    SCENE_PARAMS[1]['camera_position'] = torch.tensor(x[:3]).float()\n",
        "    SCENE_PARAMS[1]['cam_look_at'] = torch.tensor(x[3:6]).float()\n",
        "    SCENE_PARAMS[1]['cam_up'] = torch.tensor(x[6:9]/10).float()\n",
        "    SCENE_PARAMS[1]['fov'] = torch.tensor(x[9]*10).float()\n",
        "\n",
        "    scene, variables = start_up(SCENE_PARAMS, [])\n",
        "    inputs = render_input(scene)\n",
        "    inputs = inputs.cuda()\n",
        "    rendered_inputs = inputs.clone()\n",
        "    inputs = inputs/255.0\n",
        "    im_means = torch.mean(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    im_stds = torch.std(inputs).unsqueeze(0).unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
        "    inputs_ = (inputs - im_means)/im_stds\n",
        "    outputs = loaded_model(inputs_)\n",
        "    probability = outputs[0][CATEGORY_NUM].item()\n",
        "    prediction = torch.argmax(outputs[0]).item()\n",
        "    return probability, prediction"
      ],
      "metadata": {
        "id": "6bbs5qPzQZ8b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_files_pickle = '%s/rendering/shapenet_model_subsets/categories_10_models_40.pkl'%ROOT\n",
        "with open(model_files_pickle, 'rb') as F:\n",
        "    model_files = pickle.load(F)"
      ],
      "metadata": {
        "id": "8U2pEnMCUvzO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_3d_model():\n",
        "#     categories_10_models_10.pkl\n",
        "    model_files_pickle = '../rendering/shapenet_model_subsets/%s'%MODELS_PICKLE_FILE_NAME\n",
        "    with open(model_files_pickle, 'rb') as F:\n",
        "        model_files = pickle.load(F)\n",
        "    random_category = random.choice(list(model_files.keys()))\n",
        "    random_instance = random.choice(model_files[random_category]).split('/')[7]\n",
        "    model_file = '%s/ShapeNetCore.v2/%s/%s/models/model_normalized.obj'%(user_root_dir, random_category, random_instance)\n",
        "    print('Chosen model is a %s'%shapenet_class_num_to_class_name[shapenet_id_to_class_num[random_category]])\n",
        "    category_num = shapenet_id_to_class_num[random_category]\n",
        "    print('Category num is %s'%category_num)\n",
        "    return model_file, category_num, random_category, random_instance"
      ],
      "metadata": {
        "id": "uqNsynHMTlSX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = '%s/rendering/shapenet_model_subsets/subset_models/04379243_cf7c2cfb403f2819548cdb167cc8bdd/models/model_normalized.obj'%ROOT\n",
        "category = '04379243'\n",
        "instance = 'cf7c2cfb403f2819548cdb167cc8bdd'\n",
        "category_num = shapenet_id_to_class_num[category]\n",
        "print('Chosen model is a %s'%shapenet_class_num_to_class_name[shapenet_id_to_class_num[category]])\n",
        "print('Category number is %s'%category_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq10Ii52Uywp",
        "outputId": "a54a7911-344e-48a1-9173-44ae2b3af70d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen model is a table\n",
            "Category number is 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.insert(0,'%s/redner/'%ROOT)\n",
        "import redner\n",
        "import pyredner"
      ],
      "metadata": {
        "id": "QGGc4-S6YAeh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyredner.__file__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2kaXSUC7YXpU",
        "outputId": "a2b97fb9-f8cc-42df-c1b7-f9ce76c02672"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/in_distribution_adversarial_examples/redner/pyredner/__init__.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_params = []\n",
        "curr_pred = -1\n",
        "while curr_pred != category_num:\n",
        "    scene_params = get_random_scene_params(model_file)\n",
        "    original_scene_params = clone_scene_params(scene_params)\n",
        "    curr_pred, _ = render_and_predict(scene_params, [])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMmnj0zHXHSJ",
        "outputId": "9f51da41-234d-490b-cea6-435ddf340a35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/in_distribution_adversarial_examples/redner/pyredner/render_pytorch.py:214: UserWarning: Converting shape vertices from cpu to cuda:0, this can be inefficient.\n",
            "  warnings.warn('Converting shape vertices from {} to {}, this can be inefficient.'.format(shape.vertices.device, device))\n",
            "/content/in_distribution_adversarial_examples/redner/pyredner/render_pytorch.py:216: UserWarning: Converting shape indices from cpu to cuda:0, this can be inefficient.\n",
            "  warnings.warn('Converting shape indices from {} to {}, this can be inefficient.'.format(shape.indices.device, device))\n",
            "/content/in_distribution_adversarial_examples/redner/pyredner/render_pytorch.py:55: UserWarning: Converting texture from cpu to cuda:0, this can be inefficient.\n",
            "  warnings.warn('Converting texture from {} to {}, this can be inefficient.'.format(mipmap.device, device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scene construction, time: 29.15305 s\n",
            "Forward pass, time: 0.37519 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-e5bf47f53d01>:181: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  outputs = softmax_layer(loaded_model(inputs_))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scene construction, time: 0.04208 s\n",
            "Forward pass, time: 0.40112 s\n",
            "Scene construction, time: 0.04439 s\n",
            "Forward pass, time: 0.40878 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_im = _[0].clone()"
      ],
      "metadata": {
        "id": "DHs_M5f2Xblu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = np.array(scene_params[1]['camera_position'])\n",
        "cat = np.array(scene_params[1]['cam_look_at'])\n",
        "cup = np.array(scene_params[1]['cam_up'])*10\n",
        "fov = np.array(scene_params[1]['fov'])/10\n",
        "start_pos = np.hstack([cp,cat,cup,fov])"
      ],
      "metadata": {
        "id": "kJerw930c3be"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SCENE_PARAMS = clone_scene_params(scene_params)\n",
        "CATEGORY_NUM = category_num\n",
        "\n",
        "es = cma.CMAEvolutionStrategy(start_pos, 0.05)\n",
        "\n",
        "es.optimize(cma_objective_adversarial, verb_disp = True, iterations=15, correct_prediction = category_num)\n",
        "print(es.predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSqiLJ8QdGsA",
        "outputId": "b916a7f8-2d65-4dab-9848-3d435b2dd649"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scene construction, time: 0.04348 s\n",
            "Forward pass, time: 0.38482 s\n",
            "Scene construction, time: 0.04271 s\n",
            "Forward pass, time: 0.38427 s\n",
            "Scene construction, time: 0.04211 s\n",
            "Forward pass, time: 0.36859 s\n",
            "Scene construction, time: 0.04240 s\n",
            "Forward pass, time: 0.37673 s\n",
            "Scene construction, time: 0.04497 s\n",
            "Forward pass, time: 0.36189 s\n",
            "Scene construction, time: 0.04259 s\n",
            "Forward pass, time: 0.37403 s\n",
            "Scene construction, time: 0.04259 s\n",
            "Forward pass, time: 0.38038 s\n",
            "Scene construction, time: 0.04259 s\n",
            "Forward pass, time: 0.36514 s\n",
            "Scene construction, time: 0.04220 s\n",
            "Forward pass, time: 0.36503 s\n",
            "Scene construction, time: 0.04390 s\n",
            "Forward pass, time: 0.36249 s\n",
            "Adversarial found, should stop now.\n",
            "Predictions are :[1, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
            "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
            "    1     10 2.661782264709473e+00 1.0e+00 4.78e-02  4e-02  5e-02 0:32.0\n",
            "Adversarial found, trying to stop.\n",
            "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
            "    1     10 2.661782264709473e+00 1.0e+00 4.78e-02  4e-02  5e-02 0:32.0\n",
            "termination by {}\n",
            "best f-value = 2.6617822647094727\n",
            "solution = [-3.25703698 -3.73726549 -0.43858006  1.48023587  0.30828358  0.79206649\n",
            " -8.95857493  2.59014838  3.87334998  3.95139612]\n",
            "[1, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info_to_store = {}\n",
        "\n",
        "info_to_store['scene_params'] = scene_params\n",
        "info_to_store['es'] = es"
      ],
      "metadata": {
        "id": "7AomvzlJdIUG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_scene, variables = start_up(SCENE_PARAMS,[])"
      ],
      "metadata": {
        "id": "wfdplZn3dP71"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_scene, variables = start_up(scene_params, [])"
      ],
      "metadata": {
        "id": "9IebR01LdjeA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_input_new(scene):\n",
        "    img = pyredner.render_pathtracing(scene = scene, num_samples = 512, seed = 1)\n",
        "    img = torch.clamp(img, min = 0.00000001)\n",
        "    img = torch.pow(img, 1.0/2.2)\n",
        "    img = img*255/torch.max(img)\n",
        "    inputs = img.permute(2,0,1).unsqueeze(0)\n",
        "    return inputs, img"
      ],
      "metadata": {
        "id": "0uWcumXGfgMT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_inputs, orig_img = render_input_new(orig_scene)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tazzarnfALL",
        "outputId": "2ae4d667-a5f3-4175-cc01-88ce2fa2d690"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scene construction, time: 0.04940 s\n",
            "Forward pass, time: 0.65605 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_inputs, new_img = render_input_new(new_scene)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLNp7YGxfLT1",
        "outputId": "f6ffb690-1522-4ee4-ab99-310fdf2ea1fb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scene construction, time: 0.03195 s\n",
            "Forward pass, time: 0.55612 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,12))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(orig_img.detach().cpu()/255.0)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(new_img.detach().cpu()/255.0)\n",
        "plt.title('Adversarial Image')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "CeuTv6RNg6R0",
        "outputId": "40a40cd0-2a7f-43e5-b8e3-c0ed359fa9e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x864 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}