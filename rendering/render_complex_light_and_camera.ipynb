{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import random, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "machine_path = os.getcwd()\n",
    "user_root_dir = '/'.join(machine_path.split('/')[:-2])\n",
    "sys.path.insert(0,'%s/redner/'%user_root_dir)\n",
    "import pyredner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRedner location: /net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print('PyRedner location: %s'%pyredner.__file__)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset_name', type = str, required = True)\n",
    "# parser.add_argument('--model_files_pickle_name', type = str, required = True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# DATASET_NAME = args.dataset_name\n",
    "# MODEL_FILES_PICKLE_NAME = args.model_files_pickle_name\n",
    "\n",
    "DATASET_NAME = \"train_v5_shapenet\"\n",
    "MODEL_FILES_PICKLE_NAME = \"categories_10_models_10.pkl\"\n",
    "\n",
    "SHAPENET_DIR = '%s/ShapeNetCore.v2'%user_root_dir\n",
    "\n",
    "dataset_path = \"%s/differentiable_graphics_ml/data/%s\"%(user_root_dir, DATASET_NAME)\n",
    "model_files_pickle_path = '%s/differentiable_graphics_ml/rendering/shapenet_model_subsets/%s'%(user_root_dir, MODEL_FILES_PICKLE_NAME)\n",
    "\n",
    "if not os.path.isdir(dataset_path):\n",
    "    print('This is a new dataset, creating a new folder at: %s'%dataset_path)\n",
    "    os.mkdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_MIN = 5.0\n",
    "RADIUS_MAX = 8.0 \n",
    "MAX_NUM_LIGHTS = 3\n",
    "\n",
    "RADIUS_MIN_CAM = 0.5\n",
    "RADIUS_MAX_CAM = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_uniform_on_sphere(num_points, radius):\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        X = np.random.normal()\n",
    "        Y = np.random.normal()\n",
    "        Z = np.random.normal()\n",
    "\n",
    "        vector = np.array([X,Y,Z])\n",
    "        point = list(radius*vector/np.linalg.norm(vector))\n",
    "        points.append(point)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_light_positions(max_num_lights, radius_min, radius_max):\n",
    "    if max_num_lights == 1:\n",
    "        num_lights = 1\n",
    "    else:\n",
    "        num_lights = random.choice(range(1,max_num_lights+1))\n",
    "    light_positions = []\n",
    "    \n",
    "    for num in range(num_lights):\n",
    "        random_radius = random.uniform(radius_min, radius_max)\n",
    "        light_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "        light_point = torch.tensor(light_point).float()\n",
    "        light_positions.append(light_point)\n",
    "    \n",
    "    return light_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_position(light_positions):\n",
    "    smallest_radius = 10000\n",
    "    for light_position in light_positions:\n",
    "        x, y, z = light_position\n",
    "        radius = np.sqrt(x**2 + y**2 + z**2)\n",
    "        if radius < smallest_radius:\n",
    "            smallest_radius = radius\n",
    "    \n",
    "    camera_pos = generate_uniform_on_sphere(1, smallest_radius * random.uniform(0.6,0.9))\n",
    "    return torch.tensor(camera_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_intensity():\n",
    "    light_intensity = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)]).float()\n",
    "    return light_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_reflectance():\n",
    "    specular_reflectance = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)], device = pyredner.get_device()).float()\n",
    "    return specular_reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_object():\n",
    "    mat = pyredner.Material(diffuse_reflectance = get_random_reflectance(), two_sided = True)\n",
    "    \n",
    "    plane = pyredner.Object(vertices = torch.tensor([[-1.0,-1.0, 1.0],\n",
    "                                                 [-1.0, 1.0, 2.0],\n",
    "                                                 [ 1.0,-1.0, 2.0],\n",
    "                                                 [ 1.0, 1.0, 2.0]],\n",
    "                                                 device = pyredner.get_device()),\n",
    "                        indices = torch.tensor([[0, 1, 2],\n",
    "                                                [1, 3, 2]],\n",
    "                                               dtype = torch.int32,\n",
    "                                               device = pyredner.get_device()),\n",
    "                        uvs = torch.tensor([[0.05, 0.05],\n",
    "                                            [0.05, 0.95],\n",
    "                                            [0.95, 0.05],\n",
    "                                            [0.95, 0.95]], device = pyredner.get_device()),\n",
    "                        material = mat)\n",
    "    return plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_shapenet_obj(obj_path):\n",
    "    all_light_positions = get_light_positions(MAX_NUM_LIGHTS, RADIUS_MIN, RADIUS_MAX)\n",
    "    random_reflectance = get_random_reflectance()\n",
    "    camera_position = get_light_positions(1, RADIUS_MIN_CAM, RADIUS_MAX_CAM)[0]\n",
    "    \n",
    "    \n",
    "    obj_model_all = pyredner.load_obj(obj_path, return_objects=True)\n",
    "    obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "    m = pyredner.Material(specular_reflectance = random_reflectance, \\\n",
    "                          two_sided = True)\n",
    "    for part in obj_model:\n",
    "        part.material = m\n",
    "    \n",
    "    scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224))\n",
    "    scene_cam.position = camera_position\n",
    "    \n",
    "    scene_lights = []\n",
    "    light_intensities = []\n",
    "    for light_pos in all_light_positions:\n",
    "        light_intensity = get_random_intensity()\n",
    "        scene_light = pyredner.generate_quad_light(position = light_pos,\n",
    "                                         look_at = torch.zeros(3),\n",
    "                                         size = torch.tensor([0.5, 0.5]),\n",
    "                                         intensity = light_intensity,\n",
    "                                         directly_visible = False)\n",
    "        light_intensities.append(light_intensity)\n",
    "        scene_lights.append(scene_light)\n",
    "    back_plane = plane_object()\n",
    "    \n",
    "    all_objects = obj_model + [back_plane] + scene_lights\n",
    "    scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
    "    img = pyredner.render_pathtracing(scene,num_samples=256,seed=1)\n",
    "    im = torch.pow(img.data, 1.0/2.2).cpu()\n",
    "    im = im*255/torch.max(im)\n",
    "    \n",
    "    image = Image.fromarray(im.numpy().astype('uint8'))\n",
    "    \n",
    "    cat_key = model_file.split('/')[-4]\n",
    "    inst_key = model_file.split('/')[-3]\n",
    "    random_key = x = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "    \n",
    "    image_key = \"%s_%s_%s\"%(cat_key, inst_key, random_key)\n",
    "    \n",
    "    random_info = [all_light_positions, random_reflectance, camera_position, light_intensities]\n",
    "    return image, image_key, random_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files_pickle_path = '/om5/user/smadan/differentiable_graphics_ml/rendering/shapenet_model_subsets/%s'%MODEL_FILES_PICKLE_NAME\n",
    "with open(model_files_pickle_path, 'rb') as F:\n",
    "    model_files = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['02691156', '02818832', '02958343', '03001627', '03467517', '03624134', '03790512', '03928116', '03948459', '04256520', '04379243'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene construction, time: 0.04404 s\n",
      "Forward pass, time: 0.61047 s\n"
     ]
    }
   ],
   "source": [
    "category = '02818832'\n",
    "\n",
    "category_dir = \"%s/%s\"%(SHAPENET_DIR, category)\n",
    "instance_model_files = model_files[category]\n",
    "for model_file in instance_model_files:\n",
    "    model_file = model_file.replace('/om5/user/smadan',user_root_dir)\n",
    "    instance = model_file.split('/')[-3]\n",
    "    rendered_im, im_name, random_info = render_shapenet_obj(model_file)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=224x224 at 0x2B93EC175D90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
