{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import random, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "machine_path = os.getcwd()\n",
    "user_root_dir = '/'.join(machine_path.split('/')[:-2])\n",
    "sys.path.insert(0,'%s/redner/'%user_root_dir)\n",
    "import pyredner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRedner location: /net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/__init__.py\n"
     ]
    }
   ],
   "source": [
    "print('PyRedner location: %s'%pyredner.__file__)\n",
    "\n",
    "DATASET_NAME = \"train_v6_shapenet\"\n",
    "MODEL_FILES_PICKLE_NAME = \"categories_10_models_10.pkl\"\n",
    "\n",
    "SHAPENET_DIR = '%s/ShapeNetCore.v2'%user_root_dir\n",
    "\n",
    "dataset_path = \"%s/differentiable_graphics_ml/data/%s\"%(user_root_dir, DATASET_NAME)\n",
    "model_files_pickle_path = '%s/differentiable_graphics_ml/rendering/shapenet_model_subsets/%s'%(user_root_dir, MODEL_FILES_PICKLE_NAME)\n",
    "\n",
    "if not os.path.isdir(dataset_path):\n",
    "    print('This is a new dataset, creating a new folder at: %s'%dataset_path)\n",
    "    os.mkdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_uniform_on_sphere(num_points, radius):\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        X = np.random.normal()\n",
    "        Y = np.random.normal()\n",
    "        Z = np.random.normal()\n",
    "\n",
    "        vector = np.array([X,Y,Z])\n",
    "        point = list(radius*vector/np.linalg.norm(vector))\n",
    "        points.append(point)\n",
    "    return points\n",
    "\n",
    "def get_cam_position(radius_min, radius_max):\n",
    "    cam_positions = []\n",
    "    random_radius = random.uniform(radius_min, radius_max)\n",
    "    cam_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "    cam_point = torch.tensor(cam_point).float()\n",
    "    cam_positions.append(cam_point)\n",
    "    \n",
    "    return cam_positions\n",
    "\n",
    "def get_positions(min_num_lights, max_num_lights, radius_min, radius_max):\n",
    "    num_lights = random.choice(range(min_num_lights, max_num_lights + 1))\n",
    "    light_positions = []\n",
    "    \n",
    "    for num in range(num_lights):\n",
    "        random_radius = random.uniform(radius_min, radius_max)\n",
    "        light_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "        light_point = torch.tensor(light_point).float()\n",
    "        light_positions.append(light_point)\n",
    "    \n",
    "    return light_positions\n",
    "\n",
    "def get_random_intensity():\n",
    "    light_intensity = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)]).float()\n",
    "    return light_intensity\n",
    "\n",
    "def get_random_reflectance():\n",
    "    specular_reflectance = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)], device = pyredner.get_device()).float()\n",
    "    return specular_reflectance\n",
    "\n",
    "def plane_object():\n",
    "    mat = pyredner.Material(diffuse_reflectance = get_random_reflectance(), two_sided = True)\n",
    "    \n",
    "    plane = pyredner.Object(vertices = torch.tensor([[-1.0,-1.0, 1.0],\n",
    "                                                 [-1.0, 1.0, 2.0],\n",
    "                                                 [ 1.0,-1.0, 2.0],\n",
    "                                                 [ 1.0, 1.0, 2.0]],\n",
    "                                                 device = pyredner.get_device()),\n",
    "                        indices = torch.tensor([[0, 1, 2],\n",
    "                                                [1, 3, 2]],\n",
    "                                               dtype = torch.int32,\n",
    "                                               device = pyredner.get_device()),\n",
    "                        uvs = torch.tensor([[0.05, 0.05],\n",
    "                                            [0.05, 0.95],\n",
    "                                            [0.95, 0.05],\n",
    "                                            [0.95, 0.95]], device = pyredner.get_device()),\n",
    "                        material = mat)\n",
    "    return plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_look_at(radius):\n",
    "    K = 0.3\n",
    "    look_at = torch.tensor([random.uniform(0,K*radius), random.uniform(0,K*radius), random.uniform(0,K*radius)]).float()\n",
    "    return look_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_MIN = 1.0\n",
    "RADIUS_MAX = 2.0 \n",
    "MIN_NUM_LIGHTS = 3\n",
    "MAX_NUM_LIGHTS = 4\n",
    "\n",
    "RADIUS_MIN_CAM = 0.5\n",
    "RADIUS_MAX_CAM = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_shapenet_obj(obj_path):\n",
    "    all_light_positions = get_positions(MIN_NUM_LIGHTS, MAX_NUM_LIGHTS, RADIUS_MIN, RADIUS_MAX)\n",
    "    camera_position = get_cam_position(RADIUS_MIN_CAM, RADIUS_MAX_CAM)[0]\n",
    "    cam_radius = torch.sqrt(camera_position[0]**2 + camera_position[1]**2 + camera_position[2]**2).item()\n",
    "    cam_look_at = get_random_look_at(cam_radius)\n",
    "    obj_model_all = pyredner.load_obj(obj_path, return_objects=True)\n",
    "    obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "    fov = torch.tensor([random.uniform(35,100)])\n",
    "    cam_up = torch.tensor([random.uniform(-1,1), random.uniform(-1,1), random.uniform(-1,1)])\n",
    "    \n",
    "    m = pyredner.Material(diffuse_reflectance = torch.tensor([1.0, 1.0, 1.0], device='cuda:0'), \\\n",
    "                          two_sided = True)\n",
    "\n",
    "    for part in obj_model:\n",
    "        part.material = m\n",
    "\n",
    "    scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224))\n",
    "    scene_cam.position = camera_position\n",
    "    scene_cam.look_at = cam_look_at\n",
    "    scene_cam.fov = fov\n",
    "    scene_cam.up = cam_up\n",
    "\n",
    "    scene_lights = []\n",
    "    light_intensities = []\n",
    "    light_look_ats = []\n",
    "    light_sizes = []\n",
    "    \n",
    "    for light_pos in all_light_positions:\n",
    "        light_look_at = get_random_look_at(cam_radius)\n",
    "        light_intensity = get_random_intensity()\n",
    "        light_size = torch.tensor([random.uniform(0.1,5.0), random.uniform(0.1, 5.0)])\n",
    "        \n",
    "        scene_light = pyredner.generate_quad_light(position = light_pos,\n",
    "                                         look_at = light_look_at,\n",
    "                                         size = light_size,\n",
    "                                         intensity = light_intensity,\n",
    "                                         directly_visible = False)\n",
    "        \n",
    "        scene_lights.append(scene_light)\n",
    "        \n",
    "        light_look_ats.append(light_look_at)\n",
    "        light_sizes.append(light_size)\n",
    "        light_intensities.append(light_intensity)\n",
    "    \n",
    "    all_objects = obj_model + scene_lights\n",
    "    scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
    "    img = pyredner.render_pathtracing(scene,num_samples=512,seed=1)\n",
    "    im = torch.pow(img.data, 1.0/2.2).cpu()\n",
    "    im = im*255/torch.max(im)\n",
    "    \n",
    "    image = Image.fromarray(im.numpy().astype('uint8'))\n",
    "    \n",
    "    cat_key = model_file.split('/')[-4]\n",
    "    inst_key = model_file.split('/')[-3]\n",
    "    random_key = x = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "    \n",
    "    image_key = \"%s_%s_%s\"%(cat_key, inst_key, random_key)\n",
    "    \n",
    "    random_info = [all_light_positions, light_intensities, light_sizes, light_look_ats,\n",
    "                   camera_position, cam_look_at, fov, cam_up]\n",
    "    return image, image_key, random_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files_pickle_path = '/om5/user/smadan/differentiable_graphics_ml/rendering/shapenet_model_subsets/%s'%MODEL_FILES_PICKLE_NAME\n",
    "with open(model_files_pickle_path, 'rb') as F:\n",
    "    model_files = pickle.load(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['02691156', '02818832', '02958343', '03001627', '03467517', '03624134', '03790512', '03928116', '03948459', '04256520', '04379243'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_files.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/render_pytorch.py:214: UserWarning: Converting shape vertices from cpu to cuda:0, this can be inefficient.\n",
      "  warnings.warn('Converting shape vertices from {} to {}, this can be inefficient.'.format(shape.vertices.device, device))\n",
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/render_pytorch.py:216: UserWarning: Converting shape indices from cpu to cuda:0, this can be inefficient.\n",
      "  warnings.warn('Converting shape indices from {} to {}, this can be inefficient.'.format(shape.indices.device, device))\n",
      "/net/storage001.ib.cluster/om2/user/smadan/redner/pyredner/render_pytorch.py:55: UserWarning: Converting texture from cpu to cuda:0, this can be inefficient.\n",
      "  warnings.warn('Converting texture from {} to {}, this can be inefficient.'.format(mipmap.device, device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene construction, time: 0.49694 s\n",
      "Forward pass, time: 2.49363 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "category = '02691156'\n",
    "\n",
    "category_dir = \"%s/%s\"%(SHAPENET_DIR, category)\n",
    "instance_model_files = model_files[category]\n",
    "for i in range(1):\n",
    "    for model_file in instance_model_files:\n",
    "        model_file = model_file.replace('/om5/user/smadan',user_root_dir)\n",
    "        instance = model_file.split('/')[-3]\n",
    "        rendered_im, im_name, random_info = render_shapenet_obj(model_file)\n",
    "        plt.imshow(rendered_im)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_rendering_ml",
   "language": "python",
   "name": "diff_rendering_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
