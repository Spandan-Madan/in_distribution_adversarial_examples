{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRedner location: /net/coxfs01/srv/export/coxfs01/pfister_lab2/share_root/Lab/spandan/redner/pyredner/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import random, string\n",
    "\n",
    "import os\n",
    "\n",
    "machine_path = os.getcwd()\n",
    "user_root_dir = '/'.join(machine_path.split('/')[:-2])\n",
    "sys.path.insert(0,'%s/redner/'%user_root_dir)\n",
    "import pyredner\n",
    "\n",
    "print('PyRedner location: %s'%pyredner.__file__)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset_name', type = str, required = True)\n",
    "# parser.add_argument('--category', type = str, required = True)\n",
    "# parser.add_argument('--model_files_pickle_name', type = str, required = True)\n",
    "# parser.add_argument('--num_repeats', type = int, default = 400)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "DATASET_NAME = 'train_v8_cluster'\n",
    "CATEGORY = '02691156'\n",
    "MODEL_FILES_PICKLE_NAME = 'categories_10_models_10.pkl'\n",
    "NUM_REPEATS = 2\n",
    "\n",
    "# DATASET_NAME = args.dataset_name\n",
    "# MODEL_FILES_PICKLE_NAME = args.model_files_pickle_name\n",
    "# CATEGORY = args.category\n",
    "# NUM_REPEATS = args.num_repeats\n",
    "\n",
    "SHAPENET_DIR = '%s/ShapeNetCore.v2'%user_root_dir\n",
    "\n",
    "dataset_path = \"%s/differentiable_graphics_ml/data/%s\"%(user_root_dir, DATASET_NAME)\n",
    "model_files_pickle_path = '%s/differentiable_graphics_ml/rendering/shapenet_model_subsets/%s'%(user_root_dir, MODEL_FILES_PICKLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_path):\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print('Making new directory: %s'%folder_path)\n",
    "        os.mkdir(folder_path)\n",
    "create_folder(dataset_path)\n",
    "\n",
    "\n",
    "def generate_uniform_on_sphere(num_points, radius):\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        X = np.random.normal()\n",
    "        Y = np.random.normal()\n",
    "        Z = np.random.normal()\n",
    "\n",
    "        vector = np.array([X,Y,Z])\n",
    "        point = list(radius*vector/np.linalg.norm(vector))\n",
    "        points.append(point)\n",
    "    return points\n",
    "\n",
    "\n",
    "def get_cam_position(radius_min, radius_max):\n",
    "    cam_positions = []\n",
    "    random_radius = random.uniform(radius_min, radius_max)\n",
    "    cam_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "    cam_point = torch.tensor(cam_point).float()\n",
    "    cam_positions.append(cam_point)\n",
    "    \n",
    "    return cam_positions\n",
    "\n",
    "\n",
    "def get_positions(min_num_lights, max_num_lights, radius_min, radius_max):\n",
    "    num_lights = random.choice(range(min_num_lights, max_num_lights + 1))\n",
    "    light_positions = []\n",
    "    \n",
    "    for num in range(num_lights):\n",
    "        random_radius = random.uniform(radius_min, radius_max)\n",
    "        light_point = generate_uniform_on_sphere(1, random_radius)[0]\n",
    "        light_point = torch.tensor(light_point).float()\n",
    "        light_positions.append(light_point)\n",
    "    \n",
    "    return light_positions\n",
    "\n",
    "\n",
    "def get_random_intensity():\n",
    "    light_intensity = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)]).float()\n",
    "    return light_intensity\n",
    "\n",
    "\n",
    "def get_random_reflectance():\n",
    "    specular_reflectance = torch.tensor([random.uniform(0,1), \\\n",
    "                                    random.uniform(0,1), random.uniform(0,1)], device = pyredner.get_device()).float()\n",
    "    return specular_reflectance\n",
    "\n",
    "\n",
    "def get_random_look_at(radius):\n",
    "    K = 0.3\n",
    "    look_at = torch.tensor([random.uniform(0,K*radius), random.uniform(0,K*radius), random.uniform(0,K*radius)]).float()\n",
    "    return look_at\n",
    "\n",
    "\n",
    "def plane_object():\n",
    "    mat = pyredner.Material(diffuse_reflectance = get_random_reflectance(), two_sided = True)\n",
    "    \n",
    "    plane = pyredner.Object(vertices = torch.tensor([[-1.0,-1.0, 1.0],\n",
    "                                                 [-1.0, 1.0, 2.0],\n",
    "                                                 [ 1.0,-1.0, 2.0],\n",
    "                                                 [ 1.0, 1.0, 2.0]],\n",
    "                                                 device = pyredner.get_device()),\n",
    "                        indices = torch.tensor([[0, 1, 2],\n",
    "                                                [1, 3, 2]],\n",
    "                                               dtype = torch.int32,\n",
    "                                               device = pyredner.get_device()),\n",
    "                        uvs = torch.tensor([[0.05, 0.05],\n",
    "                                            [0.05, 0.95],\n",
    "                                            [0.95, 0.05],\n",
    "                                            [0.95, 0.95]], device = pyredner.get_device()),\n",
    "                        material = mat)\n",
    "    return plane\n",
    "\n",
    "\n",
    "def render_shapenet_obj(obj_path, given_scene = False, scene_info = False):\n",
    "    if given_scene == False:\n",
    "        all_light_positions = get_positions(MIN_NUM_LIGHTS, MAX_NUM_LIGHTS, RADIUS_MIN, RADIUS_MAX)\n",
    "        camera_position = get_cam_position(RADIUS_MIN_CAM, RADIUS_MAX_CAM)[0]\n",
    "        cam_radius = torch.sqrt(camera_position[0]**2 + camera_position[1]**2 + camera_position[2]**2).item()\n",
    "        cam_look_at = get_random_look_at(cam_radius)\n",
    "        obj_model_all = pyredner.load_obj(obj_path, return_objects=True)\n",
    "        obj_model = [i for i in obj_model_all if len(i.vertices)>0]\n",
    "        fov = torch.tensor([random.uniform(35,100)])\n",
    "        cam_up = torch.tensor([random.uniform(-1,1), random.uniform(-1,1), random.uniform(-1,1)])\n",
    "\n",
    "        m = pyredner.Material(diffuse_reflectance = torch.tensor([1.0, 1.0, 1.0], device='cuda:0'), \\\n",
    "                              two_sided = True)\n",
    "\n",
    "        for part in obj_model:\n",
    "            part.material = m\n",
    "\n",
    "        scene_cam = pyredner.automatic_camera_placement(obj_model, resolution = (224, 224))\n",
    "        scene_cam.position = camera_position\n",
    "        scene_cam.look_at = cam_look_at\n",
    "        scene_cam.fov = fov\n",
    "        scene_cam.up = cam_up\n",
    "\n",
    "        scene_lights = []\n",
    "        light_intensities = []\n",
    "        light_look_ats = []\n",
    "        light_sizes = []\n",
    "\n",
    "        for light_pos in all_light_positions:\n",
    "            light_look_at = get_random_look_at(cam_radius)\n",
    "            light_intensity = get_random_intensity()\n",
    "            light_size = torch.tensor([random.uniform(0.1,5.0), random.uniform(0.1, 5.0)])\n",
    "\n",
    "            scene_light = pyredner.generate_quad_light(position = light_pos,\n",
    "                                             look_at = light_look_at,\n",
    "                                             size = light_size,\n",
    "                                             intensity = light_intensity,\n",
    "                                             directly_visible = False)\n",
    "\n",
    "            scene_lights.append(scene_light)\n",
    "\n",
    "            light_look_ats.append(light_look_at)\n",
    "            light_sizes.append(light_size)\n",
    "            light_intensities.append(light_intensity)\n",
    "\n",
    "        all_objects = obj_model + scene_lights\n",
    "        scene = pyredner.Scene(objects = all_objects, camera = scene_cam)\n",
    "        random_info = [all_light_positions, light_intensities, light_sizes, light_look_ats,\n",
    "                   camera_position, cam_look_at, fov, cam_up]\n",
    "    else:\n",
    "        scene = given_scene\n",
    "        random_info = scene_info\n",
    "        \n",
    "    img = pyredner.render_pathtracing(scene,num_samples=512,seed=1)\n",
    "    im = torch.pow(img.data, 1.0/2.2).cpu()\n",
    "    im = im*255/torch.max(im)\n",
    "    \n",
    "    image = Image.fromarray(im.numpy().astype('uint8'))\n",
    "    \n",
    "    cat_key = model_file.split('/')[-4]\n",
    "    inst_key = model_file.split('/')[-3]\n",
    "    random_key = x = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "    \n",
    "    image_key = \"%s_%s_%s\"%(cat_key, inst_key, random_key)\n",
    "    \n",
    "    \n",
    "    return image, image_key, random_info, scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturbation_vector(factor_len, perturb_percent = 1):\n",
    "    if factor_len == 0:\n",
    "        factor_len = 1\n",
    "    vec = torch.tensor([random.uniform(-perturb_percent/100,perturb_percent/100) for i in range(factor_len)])\n",
    "    return 1 + vec\n",
    "\n",
    "def perturb_param(param, perturb_percent):\n",
    "    new_param = param.clone() * perturbation_vector(param.dim(), perturb_percent = 1)\n",
    "    return new_param\n",
    "\n",
    "def random_perturbed_scene(scene, perturb_percent = 1):\n",
    "    ########## Perturb Camera ############\n",
    "    camera = scene.camera\n",
    "    camera_position = camera.position\n",
    "    cam_look_at = camera.look_at\n",
    "    fov = camera.fov\n",
    "    cam_up = camera.up\n",
    "    \n",
    "    new_camera_position = perturb_param(camera_position, perturb_percent)\n",
    "    new_cam_look_at = perturb_param(cam_look_at, perturb_percent)\n",
    "    new_fov = perturb_param(fov, perturb_percent)\n",
    "    new_cam_up = perturb_param(cam_up, perturb_percent)\n",
    "    \n",
    "    camera.position = new_camera_position\n",
    "    camera.look_at = new_cam_look_at\n",
    "    camera.fov = new_fov\n",
    "    camera.up = new_cam_up    \n",
    "    \n",
    "    scene.camera = camera\n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS_MIN = 1.0\n",
    "RADIUS_MAX = 8.0 \n",
    "MIN_NUM_LIGHTS = 1\n",
    "MAX_NUM_LIGHTS = 4\n",
    "\n",
    "RADIUS_MIN_CAM = 0.5\n",
    "RADIUS_MAX_CAM = 8.0\n",
    "\n",
    "with open(model_files_pickle_path, 'rb') as F:\n",
    "    model_files = pickle.load(F)\n",
    "\n",
    "RANDOMIZED_INFORMATION_CATEGORY = {}\n",
    "total = 0\n",
    "category = CATEGORY\n",
    "category_dir = \"%s/%s\"%(SHAPENET_DIR, category)\n",
    "category_path = \"%s/%s\"%(dataset_path, category)\n",
    "create_folder(category_path)\n",
    "images_folder = \"%s/images\"%category_path\n",
    "create_folder(images_folder)\n",
    "instance_model_files = model_files[category]\n",
    "\n",
    "for model_file in instance_model_files:\n",
    "    model_file = model_file.replace('/om5/user/smadan',user_root_dir)\n",
    "    instance = model_file.split('/')[-3]\n",
    "    for repeat in range(NUM_REPEATS):\n",
    "        rendered_im, im_name, random_info, scene = render_shapenet_obj(model_file)\n",
    "        RANDOMIZED_INFORMATION_CATEGORY[im_name] = random_info\n",
    "        image_path = \"%s/%s.png\"%(images_folder, im_name)\n",
    "        rendered_im.save(image_path)\n",
    "        if total % 10 == 0:\n",
    "            with open('%s/randomized_info_%s.p'%(category_path, category),'wb') as F:\n",
    "                pickle.dump(RANDOMIZED_INFORMATION_CATEGORY, F)\n",
    "        total += 1\n",
    "        \n",
    "        perturbed_scene = scene\n",
    "        for perturbation_num in range(5):\n",
    "            perturbed_scene = random_perturbed_scene(perturbed_scene, 5)\n",
    "            rendered_im, im_name, random_info, scene = render_shapenet_obj(model_file, perturbed_scene, random_info)\n",
    "            RANDOMIZED_INFORMATION_CATEGORY[im_name] = random_info\n",
    "            image_path = \"%s/%s.png\"%(images_folder, im_name)\n",
    "            rendered_im.save(image_path)\n",
    "            if total % 10 == 0:\n",
    "                with open('%s/randomized_info_%s.p'%(category_path, category),'wb') as F:\n",
    "                    pickle.dump(RANDOMIZED_INFORMATION_CATEGORY, F)\n",
    "            total += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
